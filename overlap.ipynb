{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 20:14:48.100086: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-10 20:14:48.442296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-10 20:14:48.442329: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-10 20:14:48.444186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-10 20:14:48.680332: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-10 20:14:48.692674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 20:14:52.367377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-10 20:15:03.374216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:15:04.616113: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "from models.edsr import edsr\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_clipping(data, percentage, mode=\"max\"):\n",
    "    quantile_val = np.quantile(data, percentage)\n",
    "    if mode == \"max\":\n",
    "        data = data.clip(max=quantile_val)\n",
    "    if mode == \"min\":\n",
    "        data = data.clip(min=quantile_val)\n",
    "    return data\n",
    "\n",
    "def exp_root_norm(data, exp=2):\n",
    "    return data ** (1 / exp)\n",
    "\n",
    "def minmax_scale(images):\n",
    "    # Assuming images is a 4D array with shape (N, 32, 32)\n",
    "    min_val = np.min(images)\n",
    "    max_val = np.max(images)\n",
    "    \n",
    "    scaled_images = (images - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return scaled_images\n",
    "\n",
    "def preprocess(images):\n",
    "    images = quantile_clipping(images, 0.95, mode=\"max\")\n",
    "    images = exp_root_norm(images, exp=2)\n",
    "    images = minmax_scale(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "# def pad_to_nearest_square(matrix, num_clients):\n",
    "#     \"\"\"\n",
    "#     Pad the matrix to the nearest size that's perfectly divisible by sqrt(num_clients).\n",
    "#     \"\"\"\n",
    "#     orig_height, orig_width = matrix.shape[1:3]\n",
    "#     sqrt_clients = int(math.sqrt(num_clients))\n",
    "    \n",
    "#     target_size = math.ceil(max(orig_height, orig_width) / sqrt_clients) * sqrt_clients\n",
    "    \n",
    "#     padded = np.pad(\n",
    "#         matrix,\n",
    "#         ((0, 0), (0, target_size - orig_height), (0, target_size - orig_width), (0, 0)),\n",
    "#         mode='constant'\n",
    "#     )\n",
    "    \n",
    "#     return padded, (orig_height, orig_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def extract_node_locations(dataset):\n",
    "    if dataset == 'geant':\n",
    "        nodes = [\n",
    "            \"at1.at\", \"be1.be\", \"ch1.ch\", \"cz1.cz\", \"de1.de\", \"es1.es\", \"fr1.fr\", \"gr1.gr\",\n",
    "            \"hr1.hr\", \"hu1.hu\", \"ie1.ie\", \"il1.il\", \"it1.it\", \"lu1.lu\", \"nl1.nl\", \"ny1.ny\",\n",
    "            \"pl1.pl\", \"pt1.pt\", \"se1.se\", \"si1.si\", \"sk1.sk\", \"uk1.uk\"\n",
    "        ]\n",
    "        locations = [\n",
    "            (16.3729, 48.2091), (4.3518, 50.8469), (6.1399, 46.2038), (14.4423, 50.0785),\n",
    "            (8.6842, 50.1122), (-3.7033, 40.4167), (2.351, 48.8566), (23.5808, 37.9778),\n",
    "            (15.9644, 45.8071), (19.0936, 47.4976), (-6.2573, 53.3416), (34.8097, 32.0714),\n",
    "            (9.19, 45.4642), (6.1296, 49.6112), (4.9407, 52.3236), (-73.94384, 40.6698),\n",
    "            (16.8874, 52.3963), (-9.1363, 38.7073), (17.8742, 59.3617), (14.5148, 46.0574),\n",
    "            (17.1297, 48.1531), (-0.1264, 51.5086)\n",
    "        ]\n",
    "    elif dataset == 'germany':\n",
    "        nodes = np.load(\"CNSM/data/germany_nodes.npy\")\n",
    "        locations = np.load(\"CNSM/data/germany_locations.npy\")\n",
    "        \n",
    "    return np.array(nodes), np.array(locations)\n",
    "\n",
    "# def cluster_nodes(locations, n_clusters):\n",
    "#     from sklearn.cluster import KMeans\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "#     clusters = kmeans.fit_predict(locations)\n",
    "#     return clusters\n",
    "\n",
    "def cluster_nodes(locations, num_clients):\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    hosts_per_cluster = len(locations)//num_clients\n",
    "    num_nodes = len(locations)\n",
    "    num_clusters = num_nodes // hosts_per_cluster\n",
    "    \n",
    "    if num_nodes % hosts_per_cluster != 0:\n",
    "        raise ValueError(f\"Number of nodes ({num_nodes}) is not divisible by hosts per cluster ({hosts_per_cluster})\")\n",
    "    \n",
    "    # Initialize clusters\n",
    "    clusters = np.full(num_nodes, -1)\n",
    "    \n",
    "    # Choose initial centroids\n",
    "    centroids = [np.random.choice(num_nodes)]\n",
    "    distances = pairwise_distances(locations, locations[centroids]).reshape(-1)\n",
    "    \n",
    "    for _ in range(1, num_clusters):\n",
    "        centroids.append(np.argmax(distances))\n",
    "        distances = np.minimum(distances, pairwise_distances(locations, locations[centroids[-1]].reshape(1, -1)).reshape(-1))\n",
    "    \n",
    "    # Assign nodes to clusters\n",
    "    for cluster_id, centroid in enumerate(centroids):\n",
    "        unassigned = np.where(clusters == -1)[0]\n",
    "        distances_to_centroid = pairwise_distances(locations[unassigned], locations[centroid].reshape(1, -1)).reshape(-1)\n",
    "        closest_nodes = unassigned[np.argsort(distances_to_centroid)[:hosts_per_cluster]]\n",
    "        clusters[closest_nodes] = cluster_id\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def kmeans(locations, n_clusters):\n",
    "    kmeans = KMeans(n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(locations)\n",
    "    return clusters\n",
    "\n",
    "def pad_sub_fine_grained_matrix(fine_grained, num_hosts, c_scale_factor=2):\n",
    "    _, height, width, _ = fine_grained.shape\n",
    "    \n",
    "    # Calculate required padding\n",
    "    pad_height = math.ceil(height / c_scale_factor) * c_scale_factor - height\n",
    "    pad_width = math.ceil(width / c_scale_factor) * c_scale_factor - width\n",
    "    \n",
    "    if pad_height == 0 and pad_width == 0:\n",
    "        return fine_grained\n",
    "    \n",
    "    padded_fine_grained = np.pad(fine_grained, \n",
    "                                 ((0, 0), (0, pad_height), (0, pad_width), (0, 0)), \n",
    "                                 mode='constant')\n",
    "    \n",
    "    # Fill padding with average values\n",
    "    if pad_height > 0:\n",
    "        padded_fine_grained[:, -pad_height:, :, :] = np.mean(fine_grained[:, -1:, :, :], axis=(1, 2), keepdims=True)\n",
    "    if pad_width > 0:\n",
    "        padded_fine_grained[:, :, -pad_width:, :] = np.mean(fine_grained[:, :, -1:, :], axis=(1, 2), keepdims=True)\n",
    "    \n",
    "    return padded_fine_grained\n",
    "\n",
    "\n",
    "def create_client_data(fine_matrices, num_clients, c_scale_factor, nodes, locations, overlap_percentage):\n",
    "    print(f\"Splitting data across {num_clients} clients with {overlap_percentage}% overlap...\")\n",
    "    num_samples, height, width, channels = fine_matrices.shape\n",
    "    \n",
    "    # Calculate the size of each fine-grained sub-matrix\n",
    "    sub_hr_size = height // num_clients + overlap_percentage * len(nodes) // 100\n",
    "\n",
    "    # node_grid_size = int(np.ceil(np.sqrt(len(nodes))))\n",
    "    \n",
    "    # Adjust sub_size to be divisible by c_scale_factor\n",
    "    adj_sub_hr_size = (sub_hr_size // c_scale_factor) * c_scale_factor\n",
    "    \n",
    "    # Ensure sub_size is at least c_scale_factor\n",
    "    adj_sub_hr_size = max(adj_sub_hr_size, c_scale_factor)\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    grid_size = int(np.ceil(np.sqrt(num_clients)))\n",
    "    \n",
    "    # Resize the fine matrices\n",
    "    # resized_fine_matrices = np.zeros((num_samples, new_size, new_size, channels))\n",
    "    # resized_fine_matrices[:, :min(height, new_size), :min(width, new_size), :] = fine_matrices[:, :min(height, new_size), :min(width, new_size), :]\n",
    "    # resized_fine_matrices = np.zeros((num_samples, adj_sub_hr_size, adj_sub_hr_size, channels))\n",
    "    # resized_fine_matrices[:, :min(height, adj_sub_hr_size), :min(width, adj_sub_hr_size), :] = fine_matrices[:, :min(height, adj_sub_hr_size), :min(width, adj_sub_hr_size), :]\n",
    "    \n",
    "    # Calculate the number of overlapping nodes\n",
    "    num_overlap_nodes = int(len(nodes) * overlap_percentage / 100)\n",
    "    # Randomly select overlapping nodes\n",
    "    overlap_nodes = np.random.choice(nodes, num_overlap_nodes, replace=False)\n",
    "    remaining_nodes = [node for node in nodes if node not in overlap_nodes]\n",
    "    num_nodes_to_split = (len(remaining_nodes)//num_clients) * num_clients\n",
    "    remaining_nodes = np.random.choice(remaining_nodes, num_nodes_to_split, replace=False)\n",
    "\n",
    "    # Assign nodes to FL clients using K-means with fixed number of elements per cluster\n",
    "    remaining_nodes_locations = [locations[nodes.tolist().index(node)] for node in remaining_nodes]\n",
    "    clusters = cluster_nodes(np.array(remaining_nodes_locations), num_clients)\n",
    "    client_unique_nodes = [remaining_nodes[clusters == i] for i in range(num_clients)]\n",
    "    \n",
    "    client_data = []\n",
    "    for client in range(num_clients):\n",
    "        # Select unique nodes for this client\n",
    "        client_nodes = np.concatenate([overlap_nodes, client_unique_nodes[client]])\n",
    "        np.random.shuffle(client_nodes)\n",
    "\n",
    "        client_locations = [locations[nodes.tolist().index(node)] for node in client_nodes]\n",
    "                \n",
    "        # Create mask for selecting data for this client\n",
    "        mask = np.isin(nodes, client_nodes)\n",
    "        mask_2d = mask[:, np.newaxis] & mask[np.newaxis, :]\n",
    "        \n",
    "        # Extract data for this client\n",
    "        # We add some padding here if the clients_nodes are not divisible by c_scale_factor\n",
    "        client_fine = fine_matrices[:, mask_2d].reshape(num_samples, len(client_nodes), len(client_nodes), channels)\n",
    "        if len(client_nodes) % c_scale_factor != 0:\n",
    "            client_fine = pad_sub_fine_grained_matrix(client_fine, len(client_nodes))\n",
    "        \n",
    "        # Create low-resolution version using clustering\n",
    "        client_coarse = create_coarse_grained(client_fine, np.array(client_locations), c_scale_factor, client_nodes)\n",
    "        \n",
    "        client_data.append((client_coarse, client_fine, client_nodes, client_locations))\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "def create_coarse_grained_matrix(fine_grained_matrix, clusters):\n",
    "    n_clusters = len(np.unique(clusters))\n",
    "    coarse_grained_matrix = np.zeros((n_clusters, n_clusters))\n",
    "    \n",
    "    # Ensure fine_grained_matrix and clusters have the same size\n",
    "    valid_size = min(fine_grained_matrix.shape[0], len(clusters))\n",
    "    fine_grained_matrix = fine_grained_matrix[:valid_size, :valid_size]\n",
    "    clusters = clusters[:valid_size]\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        for j in range(n_clusters):\n",
    "            mask_i = clusters == i\n",
    "            mask_j = clusters == j\n",
    "            coarse_grained_matrix[i, j] = np.sum(fine_grained_matrix[np.ix_(mask_i, mask_j)])\n",
    "    \n",
    "    return coarse_grained_matrix\n",
    "\n",
    "def create_coarse_grained(sub_hr_matrix, locations, scale_factor, clusters):\n",
    "    num_samples, height, width, channels = sub_hr_matrix.shape\n",
    "    \n",
    "    # Calculate number of clusters\n",
    "    # n_clusters = math.ceil(height / scale_factor) * math.ceil(width / scale_factor)\n",
    "    n_clusters = height // scale_factor\n",
    "    # if height % scale_factor != 0:\n",
    "    #     raise ValueError(\"Height must be divisible by scale factor\")\n",
    "    \n",
    "    # Perform clustering\n",
    "    clusters = kmeans(locations, n_clusters)\n",
    "    \n",
    "    # Initialize coarse-grained matrix\n",
    "    coarse_height = math.floor(height / scale_factor)\n",
    "    coarse_width = math.floor(width / scale_factor)\n",
    "    \n",
    "    # Create coarse-grained matrix\n",
    "    coarse_matrix = np.array([create_coarse_grained_matrix(matrix, clusters) for matrix in sub_hr_matrix]).astype(np.float32)\n",
    "    coarse_matrix = coarse_matrix.reshape(-1, n_clusters, n_clusters, channels)\n",
    "    \n",
    "    return coarse_matrix\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "# Usage\n",
    "# dataset = 'geant'\n",
    "# scale_factor = 2\n",
    "# num_clients = 4\n",
    "# c_scale_factor = scale_factor  # This determines the downsampling factor for creating coarse-grained matrices for each client\n",
    "# path_to_data = 'CNSM/data'\n",
    "# original_size = 22\n",
    "# ground_truth = f'{dataset}_original_{original_size}.npy'\n",
    "# overlap_percentage = 25\n",
    "# NUM_ROUNDS = 20\n",
    "\n",
    "# train_file = f'{dataset}_coarse_{original_size//scale_factor}_x{scale_factor}.npy'\n",
    "# train_set = np.load(os.path.join(path_to_data, train_file)).astype(np.float32)\n",
    "# train_ground_truth = np.load(os.path.join(path_to_data, ground_truth)).astype(np.float32)\n",
    "# # node_to_index = np.load(os.path.join(path_to_data, 'node_to_index.npy'), allow_pickle=True).item()\n",
    "\n",
    "# train_set = train_set.reshape((-1, 11, 11, 1))\n",
    "# train_ground_truth = train_ground_truth.reshape((-1, 22, 22, 1))\n",
    "\n",
    "# print(f\"Train set shape: {train_set.shape}\", \"Ground truth shape:\", train_ground_truth.shape)\n",
    "\n",
    "# train_set = preprocess(train_set)\n",
    "# train_ground_truth = preprocess(train_ground_truth)\n",
    "\n",
    "# # Extract node locations and cluster them\n",
    "# nodes, locations = extract_node_locations() # for GAENT dataset\n",
    "\n",
    "# # Create client data\n",
    "# data_filename = f\"client_data_{num_clients}_x{scale_factor}_overlap_{overlap_percentage}.pkl\"\n",
    "# client_data = create_client_data(train_ground_truth, num_clients, c_scale_factor, nodes, locations, overlap_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'germany'\n",
    "\n",
    "if dataset == 'geant':\n",
    "    original_size = 22\n",
    "elif dataset == 'germany':\n",
    "    original_size = 161\n",
    "\n",
    "NUM_ROUNDS = 20\n",
    "overlap_perc = 5\n",
    "num_clients = 4\n",
    "c_scale_factor = 2  # This determines the downsampling factor for creating coarse-grained matrices for each client\n",
    "scale_factor = 2\n",
    "path_to_data = 'CNSM/data'\n",
    "ground_truth = f'{dataset}_original_{original_size}.npy'\n",
    "coarse_size = original_size // scale_factor\n",
    "fine_size = coarse_size * scale_factor\n",
    "train_file = f'{dataset}_coarse_{coarse_size}_x{scale_factor}.npy'\n",
    "coarse_size = original_size // scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset germany shape: (8993, 161, 161)\n",
      "Loading data\n",
      "Client 0 LR: (8993, 23, 23, 1) Client {i} HR (8993, 46, 46, 1)\n",
      "Client 1 LR: (8993, 23, 23, 1) Client {i} HR (8993, 46, 46, 1)\n",
      "Client 2 LR: (8993, 23, 23, 1) Client {i} HR (8993, 46, 46, 1)\n",
      "Client 3 LR: (8993, 23, 23, 1) Client {i} HR (8993, 46, 46, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess your data\n",
    "train_file = f'{dataset}_coarse_{original_size//scale_factor}_x{scale_factor}.npy'\n",
    "# train_set = np.load(os.path.join(path_to_data, train_file)).astype(np.float32)\n",
    "train_ground_truth = np.load(os.path.join(path_to_data, ground_truth)).astype(np.float32)\n",
    "print(f\"Dataset {dataset} shape:\", train_ground_truth.shape)\n",
    "# debug\n",
    "# train_ground_truth = train_ground_truth[:400]\n",
    "\n",
    "# train_set = train_set.reshape((-1, 11, 11, 1))\n",
    "if dataset == 'geant':\n",
    "    train_ground_truth = train_ground_truth.reshape((-1, 22, 22, 1))\n",
    "elif dataset == 'germany':\n",
    "    train_ground_truth = train_ground_truth.reshape((-1, 161, 161, 1))\n",
    "\n",
    "# print(f\"Train set shape: {train_set.shape}\", \"Ground truth shape:\", train_ground_truth.shape)\n",
    "\n",
    "# train_set = preprocess(train_set)\n",
    "train_ground_truth = preprocess(train_ground_truth)\n",
    "\n",
    "# Extract node locations and cluster them\n",
    "nodes, locations = extract_node_locations(dataset) # for GAENT dataset\n",
    "\n",
    "# Create client data\n",
    "# n_clients = [6, 7, 8, 9, 10]\n",
    "# percentages = [5, 25, 50, 75]\n",
    "# for num_clients in n_clients:\n",
    "#     for p in percentages:\n",
    "data_filename = f\"{dataset}_client_data_{num_clients}_x{scale_factor}_overlap_{overlap_perc}.pkl\"\n",
    "if not os.path.exists(f'CNSM/fed_data/{data_filename}'):\n",
    "    print(\"File not found, generating client data...\")\n",
    "    client_data = create_client_data(train_ground_truth, num_clients, c_scale_factor, nodes, locations, overlap_perc)\n",
    "    save_pickle(client_data, f'CNSM/fed_data/{data_filename}')\n",
    "else:\n",
    "    print(\"Loading data\")\n",
    "    client_data = load_pickle(f'CNSM/fed_data/{data_filename}')\n",
    "# Print the shape of the client data\n",
    "for i, client in enumerate(client_data):\n",
    "    print(f\"Client {i} LR:\", client[0].shape, \"Client {i} HR\", client[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 20:17:05.907200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:05.911305: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:05.911525: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:05.912280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:05.914891: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:06.607568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:06.608885: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:06.609040: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:06.609691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:06.610814: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:13.150642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.152381: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:13.152616: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:13.153350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.154486: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:13.928452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.929993: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:13.930126: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:13.930463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.931548: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:13.942398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.943577: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:13.943679: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:13.943942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.945028: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:13.956883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.958087: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:13.958232: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:13.958584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.959672: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:13.975908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.977015: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:13.977086: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:13.977317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:13.978398: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.009678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.010791: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.010861: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.011059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.012166: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.046893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.048090: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.048187: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.048448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.049562: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.088971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.090184: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.090336: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.090676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.091764: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.149348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.150546: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.150691: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.151008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.152099: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.184487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.185675: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.185817: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.186132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.187217: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.191387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.192561: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.192682: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.192972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.194076: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.202839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.204061: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.204184: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.204500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.205592: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.231747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.232948: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.233106: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.233449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.234534: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-10 20:17:14.454506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.455706: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-09-10 20:17:14.455846: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-09-10 20:17:14.456138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 20:17:14.457223: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m round_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_ROUNDS):\n\u001b[0;32m---> 56\u001b[0m     state, metrics \u001b[38;5;241m=\u001b[39m \u001b[43miterative_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_train_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:145\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    144\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 145\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:73\u001b[0m, in \u001b[0;36mSyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 73\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/common_libs/async_utils.py:66\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define the TFF model\n",
    "def model_fn():\n",
    "    keras_model = edsr(input_depth=1, scale=2, num_filters=64, num_res_blocks=8)\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=(\n",
    "            tf.TensorSpec(shape=(None, coarse_matrix_size, coarse_matrix_size, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, fine_matrix_size, fine_matrix_size, 1), dtype=tf.float32)\n",
    "        ),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    "    )\n",
    "\n",
    "def create_tf_dataset_for_client(client_data):\n",
    "    def batch_format_fn(x, y):\n",
    "        return (x, y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(client_data)\n",
    "    dataset = dataset.shuffle(buffer_size=len(client_data[0]))\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.map(batch_format_fn)\n",
    "    return dataset\n",
    "\n",
    "for overlap_perc in [5, 25, 50, 75]:\n",
    "    for num_clients in [3, 4, 5, 6, 7]:\n",
    "        # Shapes of the client data\n",
    "        if dataset == 'geant':\n",
    "            data_filename = f'CNSM/fed_data/client_data_{num_clients}_x{scale_factor}_overlap_{overlap_perc}.pkl'\n",
    "        elif dataset == 'germany':\n",
    "            data_filename = f'CNSM/fed_data/germany_client_data_{num_clients}_x{scale_factor}_overlap_{overlap_perc}.pkl'\n",
    "        if os.path.exists(data_filename):\n",
    "            client_data = load_pickle(data_filename)\n",
    "            coarse_matrix_size = client_data[0][0].shape[1]\n",
    "            fine_matrix_size = client_data[0][1].shape[1]\n",
    "        else:\n",
    "            raise ValueError(\"The file doesn't exist. Generate client data first.\")\n",
    "\n",
    "        # Convert all clients data to float 32\n",
    "        client_data = [(x[0].astype(np.float32), x[1].astype(np.float32)) for x in client_data]\n",
    "\n",
    "        client_data = [client_data[0][0][:2000], client_data[0][1][:2000]]\n",
    "\n",
    "        federated_train_data = [create_tf_dataset_for_client(cd) for cd in client_data]\n",
    "\n",
    "        # Create the federated learning process\n",
    "        iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "            model_fn,\n",
    "            client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        )\n",
    "\n",
    "        # Initialize the server state\n",
    "        state = iterative_process.initialize()\n",
    "\n",
    "        #Perform federated training\n",
    "        start = time.time()\n",
    "        for round_num in range(NUM_ROUNDS):\n",
    "            state, metrics = iterative_process.next(state, federated_train_data)\n",
    "            print(f'Round {round_num}')\n",
    "            print(metrics)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Training time: {end - start}\")\n",
    "        # Save training time\n",
    "        save_pickle(end - start, f'CNSM/fed_data/{dataset}_fed_training_time_{num_clients}_x{scale_factor}_rounds_{NUM_ROUNDS}_overlap_{overlap_perc}.pkl')\n",
    "        # Save the federated weights\n",
    "        fed_weights = state[0].trainable\n",
    "        # Save weights\n",
    "        save_pickle(fed_weights, f'CNSM/fed_data/{dataset}_fed_weights_{num_clients}_x{scale_factor}_rounds_{NUM_ROUNDS}_overlap_{overlap_perc}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (8993, 80, 80, 1) Ground truth shape: (8993, 161, 161, 1)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CNSM/fed_data/germany_fed_weights_4_x2_rounds_20_overlap_5.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m train_ground_truth \u001b[38;5;241m=\u001b[39m preprocess(train_ground_truth)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load the federated weights\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m fed_weights \u001b[38;5;241m=\u001b[39m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCNSM/fed_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_fed_weights_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_clients\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_x\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscale_factor\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_rounds_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNUM_ROUNDS\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_overlap_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moverlap_perc\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a new model and load the weights\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m edsr(input_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_res_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mload_pickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(filename):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CNSM/fed_data/germany_fed_weights_4_x2_rounds_20_overlap_5.pkl'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "train_set = np.load(os.path.join(path_to_data, train_file)).astype(np.float32)\n",
    "train_ground_truth = np.load(os.path.join(path_to_data, ground_truth)).astype(np.float32)\n",
    "\n",
    "# node_to_index = np.load(os.path.join(path_to_data, 'node_to_index.npy'), allow_pickle=True).item()\n",
    "\n",
    "train_set = train_set.reshape((-1, coarse_size, coarse_size, 1))\n",
    "train_ground_truth = train_ground_truth.reshape((-1, original_size, original_size, 1))\n",
    "print(f\"Train set shape: {train_set.shape}\", \"Ground truth shape:\", train_ground_truth.shape)\n",
    "\n",
    "train_set = preprocess(train_set)\n",
    "train_ground_truth = preprocess(train_ground_truth)\n",
    "\n",
    "# Load the federated weights\n",
    "fed_weights = load_pickle(f'CNSM/fed_data/{dataset}_fed_weights_{num_clients}_x{scale_factor}_rounds_{NUM_ROUNDS}_overlap_{overlap_perc}.pkl')\n",
    "\n",
    "# Create a new model and load the weights\n",
    "model = edsr(input_depth=1, scale=2, num_filters=64, num_res_blocks=8)\n",
    "model.set_weights(fed_weights)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(train_set))\n",
    "x_train, x_test = train_set[:train_size], train_set[train_size:]\n",
    "y_train, y_test = train_ground_truth[:train_size], train_ground_truth[train_size:]\n",
    "\n",
    "# Flatten the arrays to 1D for easier calculation\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Flatten the arrays to 1D for easier calculation\n",
    "test_predictions = model.predict(x_test)\n",
    "if test_predictions.shape[1] != y_test.shape[1]:\n",
    "    y_test = y_test[:, :test_predictions.shape[1], :test_predictions.shape[1]] # To match the model output\n",
    "y_true = y_test.flatten()\n",
    "y_pred = test_predictions.flatten()\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Optional: Calculate R-squared (coefficient of determination)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
