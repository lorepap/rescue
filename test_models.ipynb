{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from data_manager.dataset_processing import concatenate_chunks, quantile_clipping, exp_root_norm\n",
    "from memory_manager.gpu_manager import set_gpus_used\n",
    "from models.edsr import edsr\n",
    "from utils.plotting.tm_lr_hr_sr import plot_lr_hr_sr\n",
    "import matplotlib.pyplot as plt\n",
    "from config import config_centralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU Settings\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    set_gpus_used([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialization and Configuration\n",
    "TRAFFIC_MATRICES_BASE_PATH = \"/home/ubuntu/edtmsr/facebook_data/\"\n",
    "\n",
    "# Input parameters\n",
    "SCALE_FACTOR = 2\n",
    "WINDOW_SIZE = 180\n",
    "AGGREGATION_FREQ = \"10S\"\n",
    "\n",
    "NUM_HR_PIXELS = config_centralized.TM_ORIGINAL_SIZE - config_centralized.TM_ORIGINAL_SIZE % SCALE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def minmax_scale(images):\n",
    "    # Assuming images is a 4D array with shape (N, 32, 32)\n",
    "    min_val = np.min(images)\n",
    "    max_val = np.max(images)\n",
    "    \n",
    "    scaled_images = (images - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] chunk file:  2016-10-01-19-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-02-02-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-10-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-02-03-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-02-01-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-21-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-22-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-23-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-12-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-11-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-16-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-15-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-09-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-13-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-02-00-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-20-00-00.npy\n",
      "[DEBUG] chunk file:  2016-10-01-14-00-00.npy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from traffic_matrix_helper.helper import generate_training_data, create_tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    " # Load and preprocess data\n",
    "hr_original_size_path = TRAFFIC_MATRICES_BASE_PATH + f\"/traffic_matrices_{AGGREGATION_FREQ}_pod\"\n",
    "hr_original_size_path_shuffled = TRAFFIC_MATRICES_BASE_PATH + f\"/traffic_matrices_{AGGREGATION_FREQ}_pod_shuffled\"\n",
    "hr_original = concatenate_chunks(hr_original_size_path_shuffled)\n",
    "hr_original = quantile_clipping(hr_original, config_centralized.QUANTILE_PERCENTAGE)\n",
    "hr_original = exp_root_norm(hr_original, config_centralized.NORMALIZATION_EXP)\n",
    "\n",
    "# Normalize hr_original between 0 and 1\n",
    "hr_original = minmax_scale(hr_original)\n",
    "\n",
    "# Split the data into train, test, and validation sets\n",
    "train_data, test_data = train_test_split(hr_original, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_images, hr_images = generate_training_data(hr_original, crop_size=32, scale_factor=2, window_size=28)\n",
    "lr_images_val, hr_images_val = generate_training_data(val_data, crop_size=32, scale_factor=2, window_size=28)\n",
    "lr_images_test, hr_images_test = generate_training_data(test_data, crop_size=32, scale_factor=2, window_size=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126000, 28, 28, 1) (126000, 28, 28, 1)\n",
      "(20175, 28, 28, 1) (20175, 28, 28, 1)\n",
      "(25200, 28, 28, 1) (25200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(lr_images.shape, hr_images.shape)\n",
    "print(lr_images_val.shape, hr_images_val.shape)\n",
    "print(lr_images_test.shape, hr_images_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test the function\n",
    "crop_size = 32  # Replace with your crop size\n",
    "scale_factor = 2  # Replace with your scale factor\n",
    "\n",
    "# Select a random sample from hr_original\n",
    "sample_index = np.random.randint(0, len(hr_original))\n",
    "image = hr_original[sample_index]\n",
    "\n",
    "# Sample a random pair of lr_images and hr_images\n",
    "# Pick a random lr image from lr_images\n",
    "lr_index = np.random.randint(0, len(lr_images))\n",
    "lr = lr_images[lr_index]\n",
    "hr = hr_images[lr_index]\n",
    "\n",
    "# Show a sample image from hr_original\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(lr, cmap='gray')\n",
    "axs[0].set_title('LR Image', fontsize=30)\n",
    "axs[1].imshow(hr, cmap='gray')\n",
    "axs[1].set_title('HR Image (Cropped)', fontsize=30)\n",
    "axs[2].imshow(hr_original[sample_index], cmap='gray')\n",
    "axs[2].set_title('HR Image (Original)', fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import srcnn, vdsr, edsr\n",
    "\n",
    "#  Function to train any model (SRCNN in this case)\n",
    "def train_model(model: tf.keras.Model, train_images, train_labels, val_images, val_labels, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(val_images, val_labels))\n",
    "    return model\n",
    "\n",
    "# Define the model\n",
    "model_srcnn = srcnn()\n",
    "model_vdsr = vdsr()\n",
    "model_edsr = edsr(scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_srcnn = train_model(model_srcnn, lr_images, hr_images, lr_images_val, hr_images_val, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN VDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_vdsr = train_model(model_vdsr, lr_images, hr_images, lr_images_val, hr_images_val, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def PSNR(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Generate low-res and high-res pairs\n",
    "# Split the data into train, test, and validation sets\n",
    "train_data, test_data = train_test_split(hr_original, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "lr_images, hr_images = generate_training_data(hr_original, crop_size=32, scale_factor=2, window_size=28, use_edsr=True)\n",
    "lr_images_val, hr_images_val = generate_training_data(val_data, crop_size=32, scale_factor=2, window_size=28, use_edsr=True)\n",
    "lr_images_test, hr_images_test = generate_training_data(test_data, crop_size=32, scale_factor=2, window_size=28, use_edsr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESIDUAL BLOCKS TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:11:21.348306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:11:21.348618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0036 - PSNR: 24.6653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:11:31.965345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:11:31.965642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 15s 177ms/step - loss: 0.0036 - PSNR: 24.6653 - val_loss: 0.0028 - val_PSNR: 25.6346\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 0.0023 - PSNR: 26.3931 - val_loss: 0.0030 - val_PSNR: 25.2661\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.0013 - PSNR: 29.1247 - val_loss: 0.0034 - val_PSNR: 24.8030\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.4763e-04 - PSNR: 32.9210 - val_loss: 0.0036 - val_PSNR: 24.4587\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.4270e-04 - PSNR: 36.3277 - val_loss: 0.0036 - val_PSNR: 24.5456\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 1.4839e-04 - PSNR: 38.3923 - val_loss: 0.0035 - val_PSNR: 24.5832\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 1.1646e-04 - PSNR: 39.4258 - val_loss: 0.0035 - val_PSNR: 24.6178\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 1.0101e-04 - PSNR: 40.0438 - val_loss: 0.0035 - val_PSNR: 24.6494\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 8.9169e-05 - PSNR: 40.5854 - val_loss: 0.0034 - val_PSNR: 24.6791\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 8.2812e-05 - PSNR: 40.9032 - val_loss: 0.0034 - val_PSNR: 24.7418\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 7.6352e-05 - PSNR: 41.2598 - val_loss: 0.0034 - val_PSNR: 24.7747\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 7.3782e-05 - PSNR: 41.4044 - val_loss: 0.0034 - val_PSNR: 24.7891\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 7.3768e-05 - PSNR: 41.4092 - val_loss: 0.0033 - val_PSNR: 24.8174\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 6.4495e-05 - PSNR: 41.9900 - val_loss: 0.0033 - val_PSNR: 24.8303\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 6.1862e-05 - PSNR: 42.1739 - val_loss: 0.0033 - val_PSNR: 24.8588\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 5.9756e-05 - PSNR: 42.3209 - val_loss: 0.0033 - val_PSNR: 24.8697\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 5.8910e-05 - PSNR: 42.3921 - val_loss: 0.0033 - val_PSNR: 24.8415\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 5.9825e-05 - PSNR: 42.3169 - val_loss: 0.0033 - val_PSNR: 24.8987\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 5.5416e-05 - PSNR: 42.6499 - val_loss: 0.0033 - val_PSNR: 24.8954\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 5.2181e-05 - PSNR: 42.9133 - val_loss: 0.0033 - val_PSNR: 24.9230\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 5.2276e-05 - PSNR: 42.9053 - val_loss: 0.0033 - val_PSNR: 24.9283\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 5.0040e-05 - PSNR: 43.0946 - val_loss: 0.0032 - val_PSNR: 24.9450\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 4.9601e-05 - PSNR: 43.1320 - val_loss: 0.0033 - val_PSNR: 24.9180\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.8421e-05 - PSNR: 43.2406 - val_loss: 0.0032 - val_PSNR: 24.9539\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.8845e-05 - PSNR: 43.2014 - val_loss: 0.0032 - val_PSNR: 24.9721\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 4.7007e-05 - PSNR: 43.3648 - val_loss: 0.0032 - val_PSNR: 24.9742\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.6070e-05 - PSNR: 43.4527 - val_loss: 0.0032 - val_PSNR: 24.9727\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.7262e-05 - PSNR: 43.3420 - val_loss: 0.0032 - val_PSNR: 24.9942\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 4.4838e-05 - PSNR: 43.5733 - val_loss: 0.0032 - val_PSNR: 24.9859\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.3678e-05 - PSNR: 43.6831 - val_loss: 0.0032 - val_PSNR: 24.9722\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.5798e-05 - PSNR: 43.4774 - val_loss: 0.0032 - val_PSNR: 25.0197\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.3520e-05 - PSNR: 43.7033 - val_loss: 0.0032 - val_PSNR: 25.0115\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 4.1199e-05 - PSNR: 43.9433 - val_loss: 0.0032 - val_PSNR: 25.0497\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 4.1867e-05 - PSNR: 43.8690 - val_loss: 0.0032 - val_PSNR: 25.0372\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 4.0254e-05 - PSNR: 44.0435 - val_loss: 0.0032 - val_PSNR: 25.0113\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.9781e-05 - PSNR: 44.0969 - val_loss: 0.0032 - val_PSNR: 25.0513\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 4.0142e-05 - PSNR: 44.0500 - val_loss: 0.0032 - val_PSNR: 25.0416\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 3.8907e-05 - PSNR: 44.1904 - val_loss: 0.0032 - val_PSNR: 25.0667\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 3.9593e-05 - PSNR: 44.1105 - val_loss: 0.0031 - val_PSNR: 25.0738\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.7449e-05 - PSNR: 44.3577 - val_loss: 0.0032 - val_PSNR: 25.0648\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 3.7028e-05 - PSNR: 44.4020 - val_loss: 0.0031 - val_PSNR: 25.0756\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 3.6603e-05 - PSNR: 44.4560 - val_loss: 0.0032 - val_PSNR: 25.0600\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 4.0204e-05 - PSNR: 44.0480 - val_loss: 0.0032 - val_PSNR: 25.0634\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.8749e-05 - PSNR: 44.2188 - val_loss: 0.0032 - val_PSNR: 25.0656\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 5s 147ms/step - loss: 3.6879e-05 - PSNR: 44.4237 - val_loss: 0.0031 - val_PSNR: 25.0787\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 3.6774e-05 - PSNR: 44.4298 - val_loss: 0.0031 - val_PSNR: 25.1070\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.7573e-05 - PSNR: 44.3379 - val_loss: 0.0032 - val_PSNR: 25.0707\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 3.7346e-05 - PSNR: 44.3635 - val_loss: 0.0031 - val_PSNR: 25.1136\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 3.4896e-05 - PSNR: 44.6637 - val_loss: 0.0031 - val_PSNR: 25.0959\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 3.7071e-05 - PSNR: 44.3953 - val_loss: 0.0031 - val_PSNR: 25.1096\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.4218e-05 - PSNR: 44.7526 - val_loss: 0.0031 - val_PSNR: 25.1179\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.3914e-05 - PSNR: 44.7830 - val_loss: 0.0031 - val_PSNR: 25.1164\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 3.5400e-05 - PSNR: 44.5974 - val_loss: 0.0031 - val_PSNR: 25.1371\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 3.4806e-05 - PSNR: 44.6700 - val_loss: 0.0031 - val_PSNR: 25.1381\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 3.4905e-05 - PSNR: 44.6589 - val_loss: 0.0031 - val_PSNR: 25.1247\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.4280e-05 - PSNR: 44.7359 - val_loss: 0.0031 - val_PSNR: 25.1144\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 3.4336e-05 - PSNR: 44.7388 - val_loss: 0.0031 - val_PSNR: 25.1115\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 3.5163e-05 - PSNR: 44.6374 - val_loss: 0.0031 - val_PSNR: 25.1463\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.1969e-05 - PSNR: 45.0398 - val_loss: 0.0031 - val_PSNR: 25.1314\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.1259e-05 - PSNR: 45.1418 - val_loss: 0.0031 - val_PSNR: 25.1507\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.1968e-05 - PSNR: 45.0396 - val_loss: 0.0031 - val_PSNR: 25.1443\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 3.2776e-05 - PSNR: 44.9309 - val_loss: 0.0031 - val_PSNR: 25.1445\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 3.1140e-05 - PSNR: 45.1594 - val_loss: 0.0031 - val_PSNR: 25.1485\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 3.2997e-05 - PSNR: 44.9079 - val_loss: 0.0031 - val_PSNR: 25.1617\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 3.0846e-05 - PSNR: 45.2048 - val_loss: 0.0031 - val_PSNR: 25.1649\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.9508e-05 - PSNR: 45.3910 - val_loss: 0.0031 - val_PSNR: 25.1571\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 3.0105e-05 - PSNR: 45.3075 - val_loss: 0.0031 - val_PSNR: 25.1592\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 3.0964e-05 - PSNR: 45.1851 - val_loss: 0.0031 - val_PSNR: 25.1639\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.9840e-05 - PSNR: 45.3442 - val_loss: 0.0031 - val_PSNR: 25.1422\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 3.0358e-05 - PSNR: 45.2671 - val_loss: 0.0031 - val_PSNR: 25.1743\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 3.0381e-05 - PSNR: 45.2608 - val_loss: 0.0031 - val_PSNR: 25.1647\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 2.9792e-05 - PSNR: 45.3486 - val_loss: 0.0031 - val_PSNR: 25.1583\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.9086e-05 - PSNR: 45.4547 - val_loss: 0.0031 - val_PSNR: 25.1611\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.7995e-05 - PSNR: 45.6205 - val_loss: 0.0031 - val_PSNR: 25.1520\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.8514e-05 - PSNR: 45.5447 - val_loss: 0.0031 - val_PSNR: 25.1796\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 2.8269e-05 - PSNR: 45.5725 - val_loss: 0.0031 - val_PSNR: 25.1675\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 3.0694e-05 - PSNR: 45.2124 - val_loss: 0.0031 - val_PSNR: 25.1823\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.8977e-05 - PSNR: 45.4780 - val_loss: 0.0031 - val_PSNR: 25.1876\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 2.6965e-05 - PSNR: 45.7829 - val_loss: 0.0031 - val_PSNR: 25.1685\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 2.6844e-05 - PSNR: 45.8032 - val_loss: 0.0031 - val_PSNR: 25.2040\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.7507e-05 - PSNR: 45.6998 - val_loss: 0.0031 - val_PSNR: 25.1626\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.8255e-05 - PSNR: 45.5816 - val_loss: 0.0031 - val_PSNR: 25.1964\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.7876e-05 - PSNR: 45.6377 - val_loss: 0.0031 - val_PSNR: 25.1886\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.7124e-05 - PSNR: 45.7544 - val_loss: 0.0031 - val_PSNR: 25.1882\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.6475e-05 - PSNR: 45.8704 - val_loss: 0.0031 - val_PSNR: 25.1883\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 2.7009e-05 - PSNR: 45.7786 - val_loss: 0.0031 - val_PSNR: 25.1930\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.9313e-05 - PSNR: 45.4431 - val_loss: 0.0031 - val_PSNR: 25.2110\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.8790e-05 - PSNR: 45.5141 - val_loss: 0.0030 - val_PSNR: 25.2123\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.5943e-05 - PSNR: 45.9504 - val_loss: 0.0031 - val_PSNR: 25.2017\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.6918e-05 - PSNR: 45.7936 - val_loss: 0.0031 - val_PSNR: 25.1855\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.6938e-05 - PSNR: 45.7901 - val_loss: 0.0031 - val_PSNR: 25.1893\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.6760e-05 - PSNR: 45.8197 - val_loss: 0.0030 - val_PSNR: 25.2135\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 2.6985e-05 - PSNR: 45.7785 - val_loss: 0.0031 - val_PSNR: 25.1890\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 2.4833e-05 - PSNR: 46.1429 - val_loss: 0.0031 - val_PSNR: 25.2097\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 2.4297e-05 - PSNR: 46.2388 - val_loss: 0.0030 - val_PSNR: 25.2136\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 2.4663e-05 - PSNR: 46.1706 - val_loss: 0.0031 - val_PSNR: 25.1926\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 4s 144ms/step - loss: 2.4746e-05 - PSNR: 46.1543 - val_loss: 0.0031 - val_PSNR: 25.2082\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 2.6036e-05 - PSNR: 45.9394 - val_loss: 0.0030 - val_PSNR: 25.2187\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 2.4894e-05 - PSNR: 46.1311 - val_loss: 0.0030 - val_PSNR: 25.2164\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 4s 145ms/step - loss: 2.4888e-05 - PSNR: 46.1384 - val_loss: 0.0030 - val_PSNR: 25.2301\n",
      "Training time for 4 blocks: 454.0795011520386 seconds\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:18:55.770702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:18:55.771005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [1000,14,14,1]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.0057 - PSNR: 23.5193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:19:12.950688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:19:12.950981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 23s 202ms/step - loss: 0.0056 - PSNR: 23.5774 - val_loss: 0.0028 - val_PSNR: 25.5589\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.0029 - PSNR: 25.4230 - val_loss: 0.0028 - val_PSNR: 25.5395\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.0023 - PSNR: 26.4258 - val_loss: 0.0031 - val_PSNR: 25.1094\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.0015 - PSNR: 28.2802 - val_loss: 0.0035 - val_PSNR: 24.6439\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 8.5623e-04 - PSNR: 30.8448 - val_loss: 0.0037 - val_PSNR: 24.3735\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 4.6092e-04 - PSNR: 33.5485 - val_loss: 0.0038 - val_PSNR: 24.2997\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.5465e-04 - PSNR: 36.0704 - val_loss: 0.0038 - val_PSNR: 24.2645\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 1.8338e-04 - PSNR: 37.4712 - val_loss: 0.0038 - val_PSNR: 24.2716\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 1.3923e-04 - PSNR: 38.6561 - val_loss: 0.0037 - val_PSNR: 24.3421\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 1.1808e-04 - PSNR: 39.3646 - val_loss: 0.0037 - val_PSNR: 24.3451\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 1.0591e-04 - PSNR: 39.8362 - val_loss: 0.0037 - val_PSNR: 24.3801\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 9.5245e-05 - PSNR: 40.2956 - val_loss: 0.0036 - val_PSNR: 24.4382\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 9.0144e-05 - PSNR: 40.5339 - val_loss: 0.0036 - val_PSNR: 24.4706\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 8.4240e-05 - PSNR: 40.8311 - val_loss: 0.0036 - val_PSNR: 24.5157\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 7.7359e-05 - PSNR: 41.1971 - val_loss: 0.0036 - val_PSNR: 24.5232\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 7.4594e-05 - PSNR: 41.3560 - val_loss: 0.0036 - val_PSNR: 24.5472\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 7.2113e-05 - PSNR: 41.5074 - val_loss: 0.0035 - val_PSNR: 24.5730\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 6.7660e-05 - PSNR: 41.7876 - val_loss: 0.0035 - val_PSNR: 24.6023\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 6.3897e-05 - PSNR: 42.0329 - val_loss: 0.0035 - val_PSNR: 24.6263\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 6.5149e-05 - PSNR: 41.9505 - val_loss: 0.0035 - val_PSNR: 24.6507\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 6.1136e-05 - PSNR: 42.2241 - val_loss: 0.0035 - val_PSNR: 24.6550\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 6.1000e-05 - PSNR: 42.2333 - val_loss: 0.0035 - val_PSNR: 24.6553\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 5.8709e-05 - PSNR: 42.3984 - val_loss: 0.0034 - val_PSNR: 24.6981\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 5.5676e-05 - PSNR: 42.6302 - val_loss: 0.0034 - val_PSNR: 24.7225\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 5.3889e-05 - PSNR: 42.7732 - val_loss: 0.0034 - val_PSNR: 24.7257\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 5.2900e-05 - PSNR: 42.8548 - val_loss: 0.0034 - val_PSNR: 24.7275\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 5.1914e-05 - PSNR: 42.9348 - val_loss: 0.0034 - val_PSNR: 24.7321\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 5.1032e-05 - PSNR: 43.0101 - val_loss: 0.0034 - val_PSNR: 24.7871\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.9571e-05 - PSNR: 43.1360 - val_loss: 0.0034 - val_PSNR: 24.7880\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 5.0837e-05 - PSNR: 43.0261 - val_loss: 0.0034 - val_PSNR: 24.7950\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.7716e-05 - PSNR: 43.3020 - val_loss: 0.0033 - val_PSNR: 24.8094\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 4.7829e-05 - PSNR: 43.2891 - val_loss: 0.0033 - val_PSNR: 24.8143\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.6664e-05 - PSNR: 43.3985 - val_loss: 0.0033 - val_PSNR: 24.8238\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 4.6570e-05 - PSNR: 43.4083 - val_loss: 0.0033 - val_PSNR: 24.8308\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.6033e-05 - PSNR: 43.4540 - val_loss: 0.0033 - val_PSNR: 24.8453\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.5433e-05 - PSNR: 43.5161 - val_loss: 0.0033 - val_PSNR: 24.8466\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 4.4141e-05 - PSNR: 43.6399 - val_loss: 0.0033 - val_PSNR: 24.8525\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 4.5083e-05 - PSNR: 43.5459 - val_loss: 0.0033 - val_PSNR: 24.8661\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.2909e-05 - PSNR: 43.7626 - val_loss: 0.0033 - val_PSNR: 24.8844\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 5s 175ms/step - loss: 4.2560e-05 - PSNR: 43.7960 - val_loss: 0.0033 - val_PSNR: 24.8853\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.2004e-05 - PSNR: 43.8549 - val_loss: 0.0033 - val_PSNR: 24.9077\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 4.1217e-05 - PSNR: 43.9391 - val_loss: 0.0033 - val_PSNR: 24.9052\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 4.1016e-05 - PSNR: 43.9617 - val_loss: 0.0033 - val_PSNR: 24.9074\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.1932e-05 - PSNR: 43.8630 - val_loss: 0.0033 - val_PSNR: 24.9137\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 4.0705e-05 - PSNR: 43.9945 - val_loss: 0.0032 - val_PSNR: 24.9337\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.8865e-05 - PSNR: 44.1961 - val_loss: 0.0032 - val_PSNR: 24.9454\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.9687e-05 - PSNR: 44.1025 - val_loss: 0.0032 - val_PSNR: 24.9395\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.1334e-05 - PSNR: 43.9228 - val_loss: 0.0032 - val_PSNR: 24.9454\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.9435e-05 - PSNR: 44.1293 - val_loss: 0.0032 - val_PSNR: 24.9468\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.7997e-05 - PSNR: 44.2918 - val_loss: 0.0032 - val_PSNR: 24.9530\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.8324e-05 - PSNR: 44.2544 - val_loss: 0.0032 - val_PSNR: 24.9491\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.9114e-05 - PSNR: 44.1651 - val_loss: 0.0032 - val_PSNR: 24.9653\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.6790e-05 - PSNR: 44.4340 - val_loss: 0.0032 - val_PSNR: 24.9620\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.6456e-05 - PSNR: 44.4745 - val_loss: 0.0032 - val_PSNR: 24.9546\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.6874e-05 - PSNR: 44.4212 - val_loss: 0.0032 - val_PSNR: 24.9759\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 3.5408e-05 - PSNR: 44.6009 - val_loss: 0.0032 - val_PSNR: 24.9932\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.5869e-05 - PSNR: 44.5418 - val_loss: 0.0032 - val_PSNR: 24.9863\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.6028e-05 - PSNR: 44.5216 - val_loss: 0.0032 - val_PSNR: 25.0114\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.4202e-05 - PSNR: 44.7500 - val_loss: 0.0032 - val_PSNR: 24.9895\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.6130e-05 - PSNR: 44.5119 - val_loss: 0.0032 - val_PSNR: 25.0037\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 3.4302e-05 - PSNR: 44.7353 - val_loss: 0.0032 - val_PSNR: 25.0173\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.4236e-05 - PSNR: 44.7463 - val_loss: 0.0032 - val_PSNR: 25.0073\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.3456e-05 - PSNR: 44.8469 - val_loss: 0.0032 - val_PSNR: 25.0205\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.5642e-05 - PSNR: 44.5708 - val_loss: 0.0032 - val_PSNR: 25.0404\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.3454e-05 - PSNR: 44.8439 - val_loss: 0.0032 - val_PSNR: 25.0364\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.3822e-05 - PSNR: 44.7961 - val_loss: 0.0032 - val_PSNR: 25.0374\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.2679e-05 - PSNR: 44.9492 - val_loss: 0.0032 - val_PSNR: 25.0476\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.2999e-05 - PSNR: 44.9052 - val_loss: 0.0032 - val_PSNR: 25.0290\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.3168e-05 - PSNR: 44.8806 - val_loss: 0.0032 - val_PSNR: 25.0600\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.2604e-05 - PSNR: 44.9617 - val_loss: 0.0032 - val_PSNR: 25.0645\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.2670e-05 - PSNR: 44.9522 - val_loss: 0.0031 - val_PSNR: 25.0779\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 3.2818e-05 - PSNR: 44.9257 - val_loss: 0.0031 - val_PSNR: 25.0733\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.1102e-05 - PSNR: 45.1594 - val_loss: 0.0032 - val_PSNR: 25.0509\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.1981e-05 - PSNR: 45.0407 - val_loss: 0.0031 - val_PSNR: 25.0792\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 3.4295e-05 - PSNR: 44.7385 - val_loss: 0.0031 - val_PSNR: 25.0860\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 3.2915e-05 - PSNR: 44.9120 - val_loss: 0.0031 - val_PSNR: 25.0990\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 3.1188e-05 - PSNR: 45.1496 - val_loss: 0.0031 - val_PSNR: 25.0973\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.0095e-05 - PSNR: 45.3059 - val_loss: 0.0031 - val_PSNR: 25.0687\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 3.0253e-05 - PSNR: 45.2821 - val_loss: 0.0031 - val_PSNR: 25.0914\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 2.9522e-05 - PSNR: 45.3920 - val_loss: 0.0031 - val_PSNR: 25.1126\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.0879e-05 - PSNR: 45.1899 - val_loss: 0.0031 - val_PSNR: 25.1005\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.9462e-05 - PSNR: 45.3986 - val_loss: 0.0031 - val_PSNR: 25.1079\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.1254e-05 - PSNR: 45.1384 - val_loss: 0.0031 - val_PSNR: 25.1082\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 2.8357e-05 - PSNR: 45.5643 - val_loss: 0.0031 - val_PSNR: 25.1071\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 2.8685e-05 - PSNR: 45.5123 - val_loss: 0.0031 - val_PSNR: 25.1326\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 3.0201e-05 - PSNR: 45.2971 - val_loss: 0.0031 - val_PSNR: 25.1181\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 2.9291e-05 - PSNR: 45.4239 - val_loss: 0.0031 - val_PSNR: 25.1165\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 3.0299e-05 - PSNR: 45.2769 - val_loss: 0.0031 - val_PSNR: 25.1364\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 5s 147ms/step - loss: 3.0344e-05 - PSNR: 45.2695 - val_loss: 0.0031 - val_PSNR: 25.1117\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 2.8470e-05 - PSNR: 45.5457 - val_loss: 0.0031 - val_PSNR: 25.1229\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 2.7269e-05 - PSNR: 45.7309 - val_loss: 0.0031 - val_PSNR: 25.1476\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.9148e-05 - PSNR: 45.4457 - val_loss: 0.0031 - val_PSNR: 25.1309\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 2.8819e-05 - PSNR: 45.5017 - val_loss: 0.0031 - val_PSNR: 25.1238\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.9828e-05 - PSNR: 45.3628 - val_loss: 0.0031 - val_PSNR: 25.1642\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 2.7450e-05 - PSNR: 45.7049 - val_loss: 0.0031 - val_PSNR: 25.1449\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 2.8643e-05 - PSNR: 45.5219 - val_loss: 0.0031 - val_PSNR: 25.1443\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 2.6325e-05 - PSNR: 45.8853 - val_loss: 0.0031 - val_PSNR: 25.1413\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.6898e-05 - PSNR: 45.7901 - val_loss: 0.0031 - val_PSNR: 25.1488\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 2.6591e-05 - PSNR: 45.8388 - val_loss: 0.0031 - val_PSNR: 25.1603\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 2.5043e-05 - PSNR: 46.1065 - val_loss: 0.0031 - val_PSNR: 25.1440\n",
      "Training time for 8 blocks: 510.461891412735 seconds\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:27:26.821383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:27:26.821699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [1000,14,14,1]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 72 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 72 all-reduces with algorithm = nccl, num_packs = 1\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0923 - PSNR: 17.1546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:27:55.435436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:27:55.435764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 35s 257ms/step - loss: 0.0916 - PSNR: 17.1988 - val_loss: 0.0042 - val_PSNR: 23.8210\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 0.0042 - PSNR: 23.8129 - val_loss: 0.0033 - val_PSNR: 24.8232\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0035 - PSNR: 24.5761 - val_loss: 0.0031 - val_PSNR: 25.0808\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0032 - PSNR: 24.9934 - val_loss: 0.0031 - val_PSNR: 25.2105\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0030 - PSNR: 25.2898 - val_loss: 0.0030 - val_PSNR: 25.2307\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.0028 - PSNR: 25.5498 - val_loss: 0.0030 - val_PSNR: 25.2383\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.0026 - PSNR: 25.8158 - val_loss: 0.0031 - val_PSNR: 25.2046\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.0025 - PSNR: 26.1060 - val_loss: 0.0031 - val_PSNR: 25.1326\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.0023 - PSNR: 26.4323 - val_loss: 0.0032 - val_PSNR: 25.0478\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.0021 - PSNR: 26.7824 - val_loss: 0.0033 - val_PSNR: 24.9307\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.0020 - PSNR: 27.1639 - val_loss: 0.0033 - val_PSNR: 24.8129\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.0018 - PSNR: 27.5718 - val_loss: 0.0034 - val_PSNR: 24.7124\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.0016 - PSNR: 27.9655 - val_loss: 0.0035 - val_PSNR: 24.6228\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0014 - PSNR: 28.4966 - val_loss: 0.0036 - val_PSNR: 24.4670\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.0014 - PSNR: 28.8064 - val_loss: 0.0037 - val_PSNR: 24.3601\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.0011 - PSNR: 29.6049 - val_loss: 0.0038 - val_PSNR: 24.2840\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0010 - PSNR: 30.0708 - val_loss: 0.0038 - val_PSNR: 24.2101\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 6s 205ms/step - loss: 8.7425e-04 - PSNR: 30.7002 - val_loss: 0.0040 - val_PSNR: 24.0630\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 7.5352e-04 - PSNR: 31.3392 - val_loss: 0.0040 - val_PSNR: 24.0624\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 6.3973e-04 - PSNR: 32.0495 - val_loss: 0.0040 - val_PSNR: 23.9871\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 5.9301e-04 - PSNR: 32.3767 - val_loss: 0.0041 - val_PSNR: 23.9444\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 4.9474e-04 - PSNR: 33.1545 - val_loss: 0.0041 - val_PSNR: 23.8923\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 4.4681e-04 - PSNR: 33.5832 - val_loss: 0.0042 - val_PSNR: 23.8162\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 4.1148e-04 - PSNR: 33.9396 - val_loss: 0.0042 - val_PSNR: 23.8512\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 3.5805e-04 - PSNR: 34.5373 - val_loss: 0.0042 - val_PSNR: 23.8551\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 3.2217e-04 - PSNR: 34.9927 - val_loss: 0.0043 - val_PSNR: 23.7698\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 3.0825e-04 - PSNR: 35.1935 - val_loss: 0.0042 - val_PSNR: 23.8640\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 2.7777e-04 - PSNR: 35.6330 - val_loss: 0.0042 - val_PSNR: 23.8156\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 2.6107e-04 - PSNR: 35.9067 - val_loss: 0.0042 - val_PSNR: 23.8706\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 2.3851e-04 - PSNR: 36.2943 - val_loss: 0.0041 - val_PSNR: 23.8811\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 11s 354ms/step - loss: 2.2338e-04 - PSNR: 36.5759 - val_loss: 0.0041 - val_PSNR: 23.8824\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 8s 263ms/step - loss: 2.1435e-04 - PSNR: 36.7546 - val_loss: 0.0041 - val_PSNR: 23.8831\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 2.1347e-04 - PSNR: 36.7808 - val_loss: 0.0041 - val_PSNR: 23.8973\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 1.9165e-04 - PSNR: 37.2415 - val_loss: 0.0041 - val_PSNR: 23.9219\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 1.8913e-04 - PSNR: 37.2972 - val_loss: 0.0041 - val_PSNR: 23.9105\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 1.7907e-04 - PSNR: 37.5353 - val_loss: 0.0041 - val_PSNR: 23.9285\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 1.7385e-04 - PSNR: 37.6649 - val_loss: 0.0041 - val_PSNR: 23.9281\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 11s 358ms/step - loss: 1.6330e-04 - PSNR: 37.9343 - val_loss: 0.0041 - val_PSNR: 23.9477\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 7s 237ms/step - loss: 1.5723e-04 - PSNR: 38.1005 - val_loss: 0.0041 - val_PSNR: 23.9744\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.5410e-04 - PSNR: 38.1884 - val_loss: 0.0040 - val_PSNR: 23.9820\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.5851e-04 - PSNR: 38.0827 - val_loss: 0.0040 - val_PSNR: 24.0162\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 1.4398e-04 - PSNR: 38.4816 - val_loss: 0.0040 - val_PSNR: 24.0191\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 1.4055e-04 - PSNR: 38.5878 - val_loss: 0.0040 - val_PSNR: 24.0306\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 1.3786e-04 - PSNR: 38.6735 - val_loss: 0.0040 - val_PSNR: 24.0413\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.3101e-04 - PSNR: 38.8942 - val_loss: 0.0040 - val_PSNR: 24.0451\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 1.2663e-04 - PSNR: 39.0411 - val_loss: 0.0040 - val_PSNR: 24.0446\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.3302e-04 - PSNR: 38.8365 - val_loss: 0.0040 - val_PSNR: 24.0672\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 1.2177e-04 - PSNR: 39.2127 - val_loss: 0.0040 - val_PSNR: 24.0786\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.2085e-04 - PSNR: 39.2461 - val_loss: 0.0039 - val_PSNR: 24.0969\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.2007e-04 - PSNR: 39.2723 - val_loss: 0.0039 - val_PSNR: 24.0914\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 1.1463e-04 - PSNR: 39.4747 - val_loss: 0.0039 - val_PSNR: 24.1160\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.1732e-04 - PSNR: 39.3756 - val_loss: 0.0039 - val_PSNR: 24.1166\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.1086e-04 - PSNR: 39.6269 - val_loss: 0.0039 - val_PSNR: 24.1405\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.0535e-04 - PSNR: 39.8442 - val_loss: 0.0039 - val_PSNR: 24.1448\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.0421e-04 - PSNR: 39.8911 - val_loss: 0.0039 - val_PSNR: 24.1417\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 1.1202e-04 - PSNR: 39.5928 - val_loss: 0.0039 - val_PSNR: 24.1705\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 1.0413e-04 - PSNR: 39.8928 - val_loss: 0.0039 - val_PSNR: 24.1733\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 6s 204ms/step - loss: 1.0105e-04 - PSNR: 40.0253 - val_loss: 0.0039 - val_PSNR: 24.1778\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 9.6199e-05 - PSNR: 40.2411 - val_loss: 0.0039 - val_PSNR: 24.1902\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 9.4502e-05 - PSNR: 40.3176 - val_loss: 0.0039 - val_PSNR: 24.1915\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 1.0179e-04 - PSNR: 40.0035 - val_loss: 0.0039 - val_PSNR: 24.1971\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 9.6727e-05 - PSNR: 40.2144 - val_loss: 0.0039 - val_PSNR: 24.1967\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 9.1845e-05 - PSNR: 40.4413 - val_loss: 0.0038 - val_PSNR: 24.2132\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 9.1247e-05 - PSNR: 40.4692 - val_loss: 0.0038 - val_PSNR: 24.2307\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 8.8426e-05 - PSNR: 40.6068 - val_loss: 0.0038 - val_PSNR: 24.2426\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 6s 204ms/step - loss: 8.9461e-05 - PSNR: 40.5569 - val_loss: 0.0038 - val_PSNR: 24.2453\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 5s 175ms/step - loss: 9.0242e-05 - PSNR: 40.5185 - val_loss: 0.0038 - val_PSNR: 24.2473\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 173ms/step - loss: 9.0259e-05 - PSNR: 40.5185 - val_loss: 0.0038 - val_PSNR: 24.2724\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 8.4099e-05 - PSNR: 40.8256 - val_loss: 0.0038 - val_PSNR: 24.2675\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 8.4021e-05 - PSNR: 40.8309 - val_loss: 0.0038 - val_PSNR: 24.2721\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 8.4867e-05 - PSNR: 40.7847 - val_loss: 0.0038 - val_PSNR: 24.3001\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 7.9062e-05 - PSNR: 41.0945 - val_loss: 0.0038 - val_PSNR: 24.2903\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 8.0840e-05 - PSNR: 40.9966 - val_loss: 0.0038 - val_PSNR: 24.2914\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 8.2177e-05 - PSNR: 40.9238 - val_loss: 0.0038 - val_PSNR: 24.2947\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 6s 204ms/step - loss: 7.7061e-05 - PSNR: 41.2055 - val_loss: 0.0037 - val_PSNR: 24.3135\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 8.1573e-05 - PSNR: 40.9743 - val_loss: 0.0038 - val_PSNR: 24.3068\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 7.8161e-05 - PSNR: 41.1423 - val_loss: 0.0037 - val_PSNR: 24.3412\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 7.9171e-05 - PSNR: 41.0880 - val_loss: 0.0037 - val_PSNR: 24.3357\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 7.5428e-05 - PSNR: 41.2970 - val_loss: 0.0037 - val_PSNR: 24.3384\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 7.3577e-05 - PSNR: 41.4092 - val_loss: 0.0037 - val_PSNR: 24.3519\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 7.4000e-05 - PSNR: 41.3813 - val_loss: 0.0037 - val_PSNR: 24.3397\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 7.3719e-05 - PSNR: 41.3977 - val_loss: 0.0037 - val_PSNR: 24.3570\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 7.4343e-05 - PSNR: 41.3583 - val_loss: 0.0037 - val_PSNR: 24.3664\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.8635e-05 - PSNR: 41.7116 - val_loss: 0.0037 - val_PSNR: 24.3709\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 7.4635e-05 - PSNR: 41.3485 - val_loss: 0.0037 - val_PSNR: 24.3643\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 6.9090e-05 - PSNR: 41.6784 - val_loss: 0.0037 - val_PSNR: 24.3819\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 7.0450e-05 - PSNR: 41.5966 - val_loss: 0.0037 - val_PSNR: 24.3951\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.8344e-05 - PSNR: 41.7309 - val_loss: 0.0037 - val_PSNR: 24.4093\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.8669e-05 - PSNR: 41.7039 - val_loss: 0.0037 - val_PSNR: 24.4079\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 6.6750e-05 - PSNR: 41.8298 - val_loss: 0.0037 - val_PSNR: 24.4135\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 6.7563e-05 - PSNR: 41.7812 - val_loss: 0.0037 - val_PSNR: 24.4133\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 6.5280e-05 - PSNR: 41.9273 - val_loss: 0.0037 - val_PSNR: 24.4076\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 6.7240e-05 - PSNR: 41.7962 - val_loss: 0.0037 - val_PSNR: 24.4199\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.4452e-05 - PSNR: 41.9850 - val_loss: 0.0036 - val_PSNR: 24.4352\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 6.5895e-05 - PSNR: 41.8873 - val_loss: 0.0036 - val_PSNR: 24.4330\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 6.3158e-05 - PSNR: 42.0703 - val_loss: 0.0036 - val_PSNR: 24.4465\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.4604e-05 - PSNR: 41.9729 - val_loss: 0.0036 - val_PSNR: 24.4456\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.6674e-05 - PSNR: 41.8313 - val_loss: 0.0036 - val_PSNR: 24.4536\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.1080e-05 - PSNR: 42.2180 - val_loss: 0.0036 - val_PSNR: 24.4535\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 6.0723e-05 - PSNR: 42.2418 - val_loss: 0.0036 - val_PSNR: 24.4609\n",
      "Training time for 16 blocks: 657.9339144229889 seconds\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:38:25.871642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:38:25.871934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 665.8889 - PSNR: -11.6312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:39:19.532775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:39:19.533063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 63s 363ms/step - loss: 660.5674 - PSNR: -11.5258 - val_loss: 1.2899 - val_PSNR: -1.1005\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.3609 - PSNR: 5.5216 - val_loss: 0.1069 - val_PSNR: 9.7338\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 0.0895 - PSNR: 10.5579 - val_loss: 0.0706 - val_PSNR: 11.5375\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 8s 271ms/step - loss: 0.0627 - PSNR: 12.0724 - val_loss: 0.0575 - val_PSNR: 12.4233\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0501 - PSNR: 13.0439 - val_loss: 0.0470 - val_PSNR: 13.2976\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0404 - PSNR: 13.9704 - val_loss: 0.0399 - val_PSNR: 14.0133\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0332 - PSNR: 14.8298 - val_loss: 0.0335 - val_PSNR: 14.7753\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0283 - PSNR: 15.5176 - val_loss: 0.0304 - val_PSNR: 15.2028\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0250 - PSNR: 16.0580 - val_loss: 0.0287 - val_PSNR: 15.4628\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0225 - PSNR: 16.5110 - val_loss: 0.0261 - val_PSNR: 15.8677\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 8s 270ms/step - loss: 0.0206 - PSNR: 16.8979 - val_loss: 0.0249 - val_PSNR: 16.0666\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 0.0191 - PSNR: 17.2291 - val_loss: 0.0236 - val_PSNR: 16.3082\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0178 - PSNR: 17.5414 - val_loss: 0.0221 - val_PSNR: 16.5950\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0167 - PSNR: 17.8051 - val_loss: 0.0216 - val_PSNR: 16.6938\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0158 - PSNR: 18.0354 - val_loss: 0.0212 - val_PSNR: 16.7750\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0151 - PSNR: 18.2573 - val_loss: 0.0204 - val_PSNR: 16.9456\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0144 - PSNR: 18.4503 - val_loss: 0.0189 - val_PSNR: 17.2571\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0138 - PSNR: 18.6195 - val_loss: 0.0191 - val_PSNR: 17.2218\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0133 - PSNR: 18.7810 - val_loss: 0.0188 - val_PSNR: 17.2891\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 8s 264ms/step - loss: 0.0129 - PSNR: 18.9272 - val_loss: 0.0178 - val_PSNR: 17.5422\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 0.0124 - PSNR: 19.0826 - val_loss: 0.0180 - val_PSNR: 17.4995\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0120 - PSNR: 19.2226 - val_loss: 0.0170 - val_PSNR: 17.7337\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0117 - PSNR: 19.3597 - val_loss: 0.0167 - val_PSNR: 17.8124\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0114 - PSNR: 19.4678 - val_loss: 0.0167 - val_PSNR: 17.8195\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0111 - PSNR: 19.5800 - val_loss: 0.0168 - val_PSNR: 17.7883\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0108 - PSNR: 19.6883 - val_loss: 0.0155 - val_PSNR: 18.1294\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 0.0105 - PSNR: 19.8244 - val_loss: 0.0157 - val_PSNR: 18.0950\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0102 - PSNR: 19.9290 - val_loss: 0.0154 - val_PSNR: 18.1694\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 8s 251ms/step - loss: 0.0100 - PSNR: 20.0248 - val_loss: 0.0149 - val_PSNR: 18.3170\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 7s 239ms/step - loss: 0.0098 - PSNR: 20.1319 - val_loss: 0.0144 - val_PSNR: 18.4550\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0095 - PSNR: 20.2402 - val_loss: 0.0145 - val_PSNR: 18.4424\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0094 - PSNR: 20.3234 - val_loss: 0.0139 - val_PSNR: 18.6175\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 0.0092 - PSNR: 20.4147 - val_loss: 0.0135 - val_PSNR: 18.7410\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0090 - PSNR: 20.5020 - val_loss: 0.0135 - val_PSNR: 18.7331\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0088 - PSNR: 20.5878 - val_loss: 0.0139 - val_PSNR: 18.6151\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 0.0087 - PSNR: 20.6615 - val_loss: 0.0131 - val_PSNR: 18.8806\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0085 - PSNR: 20.7482 - val_loss: 0.0129 - val_PSNR: 18.9485\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.0083 - PSNR: 20.8334 - val_loss: 0.0131 - val_PSNR: 18.8842\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.0083 - PSNR: 20.8513 - val_loss: 0.0130 - val_PSNR: 18.9020\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0081 - PSNR: 20.9603 - val_loss: 0.0124 - val_PSNR: 19.1140\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0079 - PSNR: 21.0318 - val_loss: 0.0123 - val_PSNR: 19.1606\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 9s 275ms/step - loss: 0.0078 - PSNR: 21.1094 - val_loss: 0.0123 - val_PSNR: 19.1537\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0077 - PSNR: 21.1628 - val_loss: 0.0122 - val_PSNR: 19.1847\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0076 - PSNR: 21.2403 - val_loss: 0.0123 - val_PSNR: 19.1505\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0075 - PSNR: 21.2924 - val_loss: 0.0120 - val_PSNR: 19.2548\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0073 - PSNR: 21.3734 - val_loss: 0.0117 - val_PSNR: 19.3522\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 0.0073 - PSNR: 21.4223 - val_loss: 0.0118 - val_PSNR: 19.3423\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 8s 258ms/step - loss: 0.0072 - PSNR: 21.4861 - val_loss: 0.0114 - val_PSNR: 19.4833\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0071 - PSNR: 21.5288 - val_loss: 0.0111 - val_PSNR: 19.5828\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0070 - PSNR: 21.5569 - val_loss: 0.0115 - val_PSNR: 19.4466\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 9s 275ms/step - loss: 0.0069 - PSNR: 21.6388 - val_loss: 0.0115 - val_PSNR: 19.4364\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0068 - PSNR: 21.7097 - val_loss: 0.0111 - val_PSNR: 19.5773\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0067 - PSNR: 21.7693 - val_loss: 0.0110 - val_PSNR: 19.6174\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 9s 284ms/step - loss: 0.0066 - PSNR: 21.8230 - val_loss: 0.0111 - val_PSNR: 19.5987\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0066 - PSNR: 21.8667 - val_loss: 0.0110 - val_PSNR: 19.6372\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.0065 - PSNR: 21.9328 - val_loss: 0.0107 - val_PSNR: 19.7570\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 8s 271ms/step - loss: 0.0064 - PSNR: 21.9736 - val_loss: 0.0105 - val_PSNR: 19.8235\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 9s 275ms/step - loss: 0.0063 - PSNR: 22.0205 - val_loss: 0.0105 - val_PSNR: 19.8470\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0063 - PSNR: 22.0714 - val_loss: 0.0106 - val_PSNR: 19.7783\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0062 - PSNR: 22.1166 - val_loss: 0.0105 - val_PSNR: 19.8491\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0061 - PSNR: 22.1723 - val_loss: 0.0107 - val_PSNR: 19.7690\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0061 - PSNR: 22.1807 - val_loss: 0.0103 - val_PSNR: 19.9159\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 0.0060 - PSNR: 22.2695 - val_loss: 0.0101 - val_PSNR: 20.0035\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0059 - PSNR: 22.3109 - val_loss: 0.0101 - val_PSNR: 20.0103\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 0.0059 - PSNR: 22.3575 - val_loss: 0.0099 - val_PSNR: 20.0805\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 8s 269ms/step - loss: 0.0058 - PSNR: 22.3838 - val_loss: 0.0101 - val_PSNR: 19.9989\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0057 - PSNR: 22.4583 - val_loss: 0.0099 - val_PSNR: 20.0942\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0057 - PSNR: 22.5004 - val_loss: 0.0098 - val_PSNR: 20.1221\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0056 - PSNR: 22.5478 - val_loss: 0.0101 - val_PSNR: 19.9878\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0056 - PSNR: 22.5716 - val_loss: 0.0096 - val_PSNR: 20.2260\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0055 - PSNR: 22.6218 - val_loss: 0.0094 - val_PSNR: 20.2912\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0055 - PSNR: 22.6335 - val_loss: 0.0094 - val_PSNR: 20.3105\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 0.0054 - PSNR: 22.7130 - val_loss: 0.0095 - val_PSNR: 20.2537\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.0053 - PSNR: 22.7657 - val_loss: 0.0094 - val_PSNR: 20.3188\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0053 - PSNR: 22.8030 - val_loss: 0.0095 - val_PSNR: 20.2655\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0052 - PSNR: 22.8491 - val_loss: 0.0095 - val_PSNR: 20.2616\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0052 - PSNR: 22.8762 - val_loss: 0.0092 - val_PSNR: 20.4113\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0052 - PSNR: 22.8767 - val_loss: 0.0093 - val_PSNR: 20.3637\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0051 - PSNR: 22.9500 - val_loss: 0.0093 - val_PSNR: 20.3715\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0050 - PSNR: 23.0090 - val_loss: 0.0091 - val_PSNR: 20.4735\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0050 - PSNR: 23.0385 - val_loss: 0.0089 - val_PSNR: 20.5301\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 0.0050 - PSNR: 23.0771 - val_loss: 0.0090 - val_PSNR: 20.5085\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 0.0049 - PSNR: 23.1117 - val_loss: 0.0089 - val_PSNR: 20.5489\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0049 - PSNR: 23.1634 - val_loss: 0.0088 - val_PSNR: 20.6189\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 0.0048 - PSNR: 23.2054 - val_loss: 0.0088 - val_PSNR: 20.6187\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0048 - PSNR: 23.2145 - val_loss: 0.0088 - val_PSNR: 20.6224\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0047 - PSNR: 23.2741 - val_loss: 0.0086 - val_PSNR: 20.6990\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.0047 - PSNR: 23.3048 - val_loss: 0.0087 - val_PSNR: 20.6761\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0047 - PSNR: 23.3002 - val_loss: 0.0085 - val_PSNR: 20.7375\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0047 - PSNR: 23.3527 - val_loss: 0.0085 - val_PSNR: 20.7384\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.0046 - PSNR: 23.4292 - val_loss: 0.0085 - val_PSNR: 20.7521\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 7s 240ms/step - loss: 0.0046 - PSNR: 23.4498 - val_loss: 0.0085 - val_PSNR: 20.7568\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0045 - PSNR: 23.4984 - val_loss: 0.0083 - val_PSNR: 20.8412\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.0045 - PSNR: 23.5324 - val_loss: 0.0083 - val_PSNR: 20.8542\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.0044 - PSNR: 23.5567 - val_loss: 0.0085 - val_PSNR: 20.7699\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0045 - PSNR: 23.5389 - val_loss: 0.0082 - val_PSNR: 20.9125\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0044 - PSNR: 23.6474 - val_loss: 0.0082 - val_PSNR: 20.8992\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.0043 - PSNR: 23.6638 - val_loss: 0.0081 - val_PSNR: 20.9538\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0043 - PSNR: 23.6952 - val_loss: 0.0082 - val_PSNR: 20.8832\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 0.0043 - PSNR: 23.7467 - val_loss: 0.0080 - val_PSNR: 21.0082\n",
      "Training time for 32 blocks: 899.613213300705 seconds\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:53:27.454677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:53:27.455080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [1000,14,14,1]\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2205646592.0000 - PSNR: -75.5392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:55:14.547957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 21:55:14.548243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 122s 557ms/step - loss: 2205646592.0000 - PSNR: -75.5392 - val_loss: 1344346.0000 - val_PSNR: -61.2766\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 304645.1875 - PSNR: -52.5242 - val_loss: 36590.8789 - val_PSNR: -45.6280\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 24881.9102 - PSNR: -43.7727 - val_loss: 14055.5674 - val_PSNR: -41.4713\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 12440.8477 - PSNR: -40.9027 - val_loss: 8997.7480 - val_PSNR: -39.5336\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 8570.5039 - PSNR: -39.3012 - val_loss: 6572.6611 - val_PSNR: -38.1693\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 6514.9448 - PSNR: -38.1163 - val_loss: 5141.6250 - val_PSNR: -37.1025\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 5234.7290 - PSNR: -37.1687 - val_loss: 4194.4917 - val_PSNR: -36.2181\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 4344.8584 - PSNR: -36.3605 - val_loss: 3519.7344 - val_PSNR: -35.4559\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 3679.1074 - PSNR: -35.6370 - val_loss: 3008.6062 - val_PSNR: -34.7734\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 3160.9177 - PSNR: -34.9773 - val_loss: 2605.7251 - val_PSNR: -34.1481\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 2748.4973 - PSNR: -34.3706 - val_loss: 2283.9736 - val_PSNR: -33.5746\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 2414.5410 - PSNR: -33.8080 - val_loss: 2019.8475 - val_PSNR: -33.0396\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 2141.3679 - PSNR: -33.2858 - val_loss: 1813.8395 - val_PSNR: -32.5696\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1913.9050 - PSNR: -32.7977 - val_loss: 1631.5122 - val_PSNR: -32.1077\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 1724.9630 - PSNR: -32.3459 - val_loss: 1485.0734 - val_PSNR: -31.6970\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 11s 350ms/step - loss: 1566.3760 - PSNR: -31.9272 - val_loss: 1358.6361 - val_PSNR: -31.3094\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 12s 380ms/step - loss: 1432.8324 - PSNR: -31.5398 - val_loss: 1266.5857 - val_PSNR: -30.9976\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 1318.8147 - PSNR: -31.1800 - val_loss: 1179.3218 - val_PSNR: -30.6842\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1222.0302 - PSNR: -30.8485 - val_loss: 1106.1353 - val_PSNR: -30.4018\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 12s 396ms/step - loss: 1139.1895 - PSNR: -30.5441 - val_loss: 1056.9923 - val_PSNR: -30.1933\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 1068.2633 - PSNR: -30.2650 - val_loss: 989.5205 - val_PSNR: -29.9087\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 1005.9176 - PSNR: -30.0035 - val_loss: 947.3963 - val_PSNR: -29.7120\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 951.8257 - PSNR: -29.7630 - val_loss: 918.5015 - val_PSNR: -29.5643\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 12s 370ms/step - loss: 904.6926 - PSNR: -29.5427 - val_loss: 877.8849 - val_PSNR: -29.3658\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 862.0527 - PSNR: -29.3328 - val_loss: 845.0919 - val_PSNR: -29.1935\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 823.6585 - PSNR: -29.1347 - val_loss: 815.1467 - val_PSNR: -29.0318\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 788.9756 - PSNR: -28.9482 - val_loss: 786.9482 - val_PSNR: -28.8753\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 757.9066 - PSNR: -28.7741 - val_loss: 757.7986 - val_PSNR: -28.7110\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 729.5939 - PSNR: -28.6083 - val_loss: 734.0805 - val_PSNR: -28.5702\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 702.9068 - PSNR: -28.4467 - val_loss: 728.2530 - val_PSNR: -28.5149\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 11s 359ms/step - loss: 678.7396 - PSNR: -28.2945 - val_loss: 705.4026 - val_PSNR: -28.3745\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 656.6091 - PSNR: -28.1504 - val_loss: 681.8040 - val_PSNR: -28.2270\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 635.6351 - PSNR: -28.0094 - val_loss: 669.2413 - val_PSNR: -28.1392\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 615.1860 - PSNR: -27.8675 - val_loss: 644.2876 - val_PSNR: -27.9798\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 596.6136 - PSNR: -27.7348 - val_loss: 633.4744 - val_PSNR: -27.8959\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 579.1002 - PSNR: -27.6051 - val_loss: 617.5319 - val_PSNR: -27.7850\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 12s 392ms/step - loss: 562.8025 - PSNR: -27.4812 - val_loss: 601.3696 - val_PSNR: -27.6694\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 11s 347ms/step - loss: 546.7216 - PSNR: -27.3552 - val_loss: 595.7772 - val_PSNR: -27.6141\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 531.7134 - PSNR: -27.2346 - val_loss: 577.5750 - val_PSNR: -27.4860\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 517.3395 - PSNR: -27.1156 - val_loss: 562.8511 - val_PSNR: -27.3761\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 504.1108 - PSNR: -27.0029 - val_loss: 552.3242 - val_PSNR: -27.2900\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 491.1318 - PSNR: -26.8896 - val_loss: 543.5720 - val_PSNR: -27.2162\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 478.4667 - PSNR: -26.7765 - val_loss: 531.7240 - val_PSNR: -27.1210\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 466.7177 - PSNR: -26.6686 - val_loss: 518.9771 - val_PSNR: -27.0191\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 455.3764 - PSNR: -26.5619 - val_loss: 515.6593 - val_PSNR: -26.9783\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 444.6312 - PSNR: -26.4581 - val_loss: 499.8884 - val_PSNR: -26.8595\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 434.5806 - PSNR: -26.3590 - val_loss: 498.3126 - val_PSNR: -26.8256\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 424.0721 - PSNR: -26.2526 - val_loss: 488.1440 - val_PSNR: -26.7379\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 414.5348 - PSNR: -26.1539 - val_loss: 488.9828 - val_PSNR: -26.7227\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 405.9090 - PSNR: -26.0622 - val_loss: 476.4346 - val_PSNR: -26.6211\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 396.3111 - PSNR: -25.9585 - val_loss: 465.0495 - val_PSNR: -26.5215\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 387.6871 - PSNR: -25.8632 - val_loss: 461.2220 - val_PSNR: -26.4736\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 12s 396ms/step - loss: 379.3730 - PSNR: -25.7691 - val_loss: 459.9423 - val_PSNR: -26.4485\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 371.3226 - PSNR: -25.6757 - val_loss: 447.4583 - val_PSNR: -26.3401\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 363.4856 - PSNR: -25.5828 - val_loss: 446.6400 - val_PSNR: -26.3159\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 356.1093 - PSNR: -25.4941 - val_loss: 434.8358 - val_PSNR: -26.2106\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 349.2268 - PSNR: -25.4089 - val_loss: 438.5221 - val_PSNR: -26.2199\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 342.5342 - PSNR: -25.3247 - val_loss: 423.9026 - val_PSNR: -26.0909\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 11s 348ms/step - loss: 335.0279 - PSNR: -25.2289 - val_loss: 417.0558 - val_PSNR: -26.0170\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 12s 387ms/step - loss: 328.8471 - PSNR: -25.1481 - val_loss: 419.6729 - val_PSNR: -26.0240\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 322.2774 - PSNR: -25.0599 - val_loss: 407.7121 - val_PSNR: -25.9097\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 315.9887 - PSNR: -24.9744 - val_loss: 398.3832 - val_PSNR: -25.8178\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 310.2332 - PSNR: -24.8947 - val_loss: 403.5118 - val_PSNR: -25.8444\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 304.2563 - PSNR: -24.8097 - val_loss: 391.8398 - val_PSNR: -25.7290\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 298.3303 - PSNR: -24.7241 - val_loss: 397.1745 - val_PSNR: -25.7624\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 11s 362ms/step - loss: 293.6562 - PSNR: -24.6554 - val_loss: 378.9142 - val_PSNR: -25.5898\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 12s 374ms/step - loss: 287.5215 - PSNR: -24.5637 - val_loss: 375.4002 - val_PSNR: -25.5400\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 282.4305 - PSNR: -24.4863 - val_loss: 366.9515 - val_PSNR: -25.4497\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 277.7585 - PSNR: -24.4135 - val_loss: 366.2834 - val_PSNR: -25.4273\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 272.8744 - PSNR: -24.3360 - val_loss: 350.3731 - val_PSNR: -25.2774\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 268.2343 - PSNR: -24.2613 - val_loss: 366.3553 - val_PSNR: -25.3994\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 262.9853 - PSNR: -24.1756 - val_loss: 351.8601 - val_PSNR: -25.2484\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 258.4816 - PSNR: -24.1006 - val_loss: 355.6274 - val_PSNR: -25.2677\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 11s 361ms/step - loss: 254.1619 - PSNR: -24.0269 - val_loss: 341.3254 - val_PSNR: -25.1171\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 250.2042 - PSNR: -23.9585 - val_loss: 349.9748 - val_PSNR: -25.1872\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 246.0117 - PSNR: -23.8848 - val_loss: 335.4492 - val_PSNR: -25.0313\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 241.6574 - PSNR: -23.8076 - val_loss: 339.2124 - val_PSNR: -25.0520\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 237.9353 - PSNR: -23.7391 - val_loss: 325.5533 - val_PSNR: -24.9025\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 233.8454 - PSNR: -23.6643 - val_loss: 326.4647 - val_PSNR: -24.8955\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 12s 392ms/step - loss: 230.5656 - PSNR: -23.6023 - val_loss: 331.0243 - val_PSNR: -24.9282\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 11s 348ms/step - loss: 226.8118 - PSNR: -23.5309 - val_loss: 324.1942 - val_PSNR: -24.8434\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 222.7311 - PSNR: -23.4521 - val_loss: 314.1582 - val_PSNR: -24.7240\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 219.5995 - PSNR: -23.3907 - val_loss: 317.2393 - val_PSNR: -24.7424\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 216.0455 - PSNR: -23.3191 - val_loss: 308.3848 - val_PSNR: -24.6339\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 212.5730 - PSNR: -23.2492 - val_loss: 299.9392 - val_PSNR: -24.5273\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 209.4193 - PSNR: -23.1835 - val_loss: 299.0626 - val_PSNR: -24.5047\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 206.0329 - PSNR: -23.1133 - val_loss: 290.6474 - val_PSNR: -24.3981\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 203.0637 - PSNR: -23.0500 - val_loss: 297.8307 - val_PSNR: -24.4625\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 12s 398ms/step - loss: 200.0032 - PSNR: -22.9834 - val_loss: 290.7030 - val_PSNR: -24.3684\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 12s 399ms/step - loss: 196.9922 - PSNR: -22.9181 - val_loss: 283.1184 - val_PSNR: -24.2693\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 12s 401ms/step - loss: 194.0048 - PSNR: -22.8513 - val_loss: 288.4226 - val_PSNR: -24.3171\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 191.4470 - PSNR: -22.7924 - val_loss: 282.8898 - val_PSNR: -24.2387\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 12s 396ms/step - loss: 188.5179 - PSNR: -22.7264 - val_loss: 276.7410 - val_PSNR: -24.1513\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 185.6707 - PSNR: -22.6603 - val_loss: 276.4435 - val_PSNR: -24.1348\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 182.9733 - PSNR: -22.5964 - val_loss: 267.9933 - val_PSNR: -24.0186\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 180.4170 - PSNR: -22.5354 - val_loss: 270.0911 - val_PSNR: -24.0284\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 12s 400ms/step - loss: 177.8608 - PSNR: -22.4733 - val_loss: 267.3508 - val_PSNR: -23.9835\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 175.3112 - PSNR: -22.4106 - val_loss: 260.0117 - val_PSNR: -23.8785\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 172.9107 - PSNR: -22.3501 - val_loss: 255.1497 - val_PSNR: -23.8028\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 171.0253 - PSNR: -22.3015 - val_loss: 258.9704 - val_PSNR: -23.8391\n",
      "Training time for 64 blocks: 1330.8613195419312 seconds\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 22:15:42.427202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 22:15:42.427566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [1000,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: nan - PSNR: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 22:19:29.159369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-10-10 22:19:29.159662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [20175,28,28,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 253s 985ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 20s 655ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 21s 686ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 21s 684ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 20s 647ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 21s 659ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 21s 684ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 21s 679ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 20s 655ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 16s 517ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 16s 510ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 17s 561ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 19s 606ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 21s 677ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 20s 631ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 22s 691ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 20s 630ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 21s 671ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 21s 681ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 20s 649ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 21s 669ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 20s 645ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 20s 654ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 20s 655ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 21s 660ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 21s 685ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 20s 653ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 20s 651ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 21s 677ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 21s 679ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 20s 653ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 20s 654ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 21s 662ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 20s 642ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 21s 681ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 21s 661ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 20s 656ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 21s 679ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 21s 667ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 20s 648ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 21s 683ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 21s 672ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 20s 643ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 22s 690ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 21s 666ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 20s 633ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 21s 673ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 19s 624ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 19s 625ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 21s 687ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 19s 624ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 21s 681ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 22s 699ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 22s 694ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 19s 614ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 21s 686ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 21s 687ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 21s 677ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 19s 609ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 21s 680ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 21s 676ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 21s 681ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 19s 606ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 21s 679ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 21s 677ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 21s 681ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 19s 604ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 21s 678ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 21s 666ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 19s 613ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 21s 682ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 21s 675ms/step - loss: nan - PSNR: nan - val_loss: nan - val_PSNR: nan\n",
      "Training time for 128 blocks: 2300.1310606002808 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "folder = '/home/ubuntu/edtmsr/www_sub'\n",
    "t_time_list = []\n",
    "lr_images = lr_images[:1000]\n",
    "hr_images = hr_images[:1000]\n",
    "for b in [4, 8, 16, 32, 64, 128]:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = edsr(scale=2, num_res_blocks=b)\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=[PSNR])\n",
    "        start_time = time.time()\n",
    "        history = model.fit(lr_images, hr_images, epochs=100, batch_size=32, validation_data=(lr_images_val, hr_images_val))\n",
    "        end_time = time.time()\n",
    "        t_time_list.append(end_time - start_time)\n",
    "        print(f\"Training time for {b} blocks: {end_time - start_time} seconds\")\n",
    "        history = pd.DataFrame(model.history.history)\n",
    "        history.to_csv(os.path.join(folder, f\"edsr_{b}_blocks.csv\"))\n",
    "# Convert the list to a numpy array\n",
    "t_time = np.array(t_time_list)\n",
    "# Save the numpy array to a file\n",
    "np.save(os.path.join(folder, \"training_times.npy\"), t_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
