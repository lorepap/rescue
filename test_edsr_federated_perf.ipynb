{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 00:27:42.988921: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-10 00:27:43.066132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-10 00:27:43.066186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-10 00:27:43.066210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-10 00:27:43.075590: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-10 00:27:43.076707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 00:27:44.575832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-10 00:27:48.489153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 00:27:48.702567: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "from models.edsr import edsr\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_clipping(data, percentage, mode=\"max\"):\n",
    "    quantile_val = np.quantile(data, percentage)\n",
    "    if mode == \"max\":\n",
    "        data = data.clip(max=quantile_val)\n",
    "    if mode == \"min\":\n",
    "        data = data.clip(min=quantile_val)\n",
    "    return data\n",
    "\n",
    "def exp_root_norm(data, exp=2):\n",
    "    return data ** (1 / exp)\n",
    "\n",
    "def minmax_scale(images):\n",
    "    # Assuming images is a 4D array with shape (N, 32, 32)\n",
    "    min_val = np.min(images)\n",
    "    max_val = np.max(images)\n",
    "    \n",
    "    scaled_images = (images - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return scaled_images\n",
    "\n",
    "def preprocess(images):\n",
    "    images = quantile_clipping(images, 0.95, mode=\"max\")\n",
    "    images = exp_root_norm(images, exp=2)\n",
    "    images = minmax_scale(images)\n",
    "    return images\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_data(fine_matrices, coarse_matrices, num_clients, scale_factor):\n",
    "    print(f\"Distributing different full-size matrices across {num_clients} clients...\")\n",
    "    \n",
    "    num_samples = fine_matrices.shape[0]\n",
    "    samples_per_client = num_samples // num_clients\n",
    "\n",
    "    fine_size = fine_matrices.shape[0]\n",
    "    coarse_size = fine_matrices.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    client_data = []\n",
    "    for i in range(num_clients):\n",
    "        start_idx = i * samples_per_client\n",
    "        end_idx = start_idx + samples_per_client if i < num_clients - 1 else num_samples\n",
    "        \n",
    "        client_fine = fine_matrices[start_idx:end_idx]\n",
    "        client_coarse = coarse_matrices[start_idx:end_idx]\n",
    "        \n",
    "        client_data.append((client_coarse, client_fine))\n",
    "    \n",
    "    return client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "dataset = 'geant'\n",
    "if dataset == 'geant':\n",
    "    original_size = 22\n",
    "elif dataset == 'germany':\n",
    "    original_size = 161\n",
    "\n",
    "scale_factor = 2\n",
    "num_clients = 2\n",
    "path_to_data = 'CNSM/data'\n",
    "ground_truth = f'{dataset}_original_{original_size}.npy'\n",
    "NUM_ROUNDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (985, 7, 7, 1) Ground truth shape: (985, 22, 22, 1)\n",
      "Distributing different full-size matrices across 2 clients...\n",
      "Client 0 LR: (492, 7, 7, 1) Client {i} HR: (492, 22, 22, 1)\n",
      "Client 1 LR: (493, 7, 7, 1) Client {i} HR: (493, 22, 22, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/templates/model_delta_client_work.py\", line 196, in reduce_fn  *\n        output = model.forward_pass(batch, training=True)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/loop_builder.py\", line 47, in _dataset_reduce_fn  *\n        return dataset.reduce(initial_state=initial_state_fn(), reduce_func=reduce_fn)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/models/keras_utils.py\", line 499, in forward_pass  *\n        return self._forward_pass(batch_input, training=training)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/models/keras_utils.py\", line 462, in _forward_pass  *\n        batch_loss = tf.add_n(\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 21 and 22 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](StatefulPartitionedCall, batch_input_1)' with input shapes: [?,21,21,1], [?,22,22,1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m federated_train_data \u001b[38;5;241m=\u001b[39m [create_tf_dataset_for_client(cd) \u001b[38;5;28;01mfor\u001b[39;00m cd \u001b[38;5;129;01min\u001b[39;00m client_data]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create the federated learning process\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m iterative_process \u001b[38;5;241m=\u001b[39m \u001b[43mtff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_weighted_fed_avg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_optimizer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_optimizer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Initialize the server state\u001b[39;00m\n\u001b[1;32m     64\u001b[0m state \u001b[38;5;241m=\u001b[39m iterative_process\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg.py:262\u001b[0m, in \u001b[0;36mbuild_weighted_fed_avg\u001b[0;34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weighting, model_distributor, model_aggregator, metrics_aggregator, loop_implementation)\u001b[0m\n\u001b[1;32m    252\u001b[0m   client_work \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    253\u001b[0m       model_delta_client_work\u001b[38;5;241m.\u001b[39mbuild_functional_model_delta_client_work(\n\u001b[1;32m    254\u001b[0m           model\u001b[38;5;241m=\u001b[39mmodel_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m       )\n\u001b[1;32m    260\u001b[0m   )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m   client_work \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_delta_client_work\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model_delta_client_work\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_optimizer_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclient_weighting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_weighting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmetrics_aggregator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_aggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m finalizer \u001b[38;5;241m=\u001b[39m apply_optimizer_finalizer\u001b[38;5;241m.\u001b[39mbuild_apply_optimizer_finalizer(\n\u001b[1;32m    270\u001b[0m     server_optimizer_fn, model_weights_type\n\u001b[1;32m    271\u001b[0m )\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m composers\u001b[38;5;241m.\u001b[39mcompose_learning_process(\n\u001b[1;32m    273\u001b[0m     initial_model_weights_fn,\n\u001b[1;32m    274\u001b[0m     model_distributor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m     finalizer,\n\u001b[1;32m    278\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/templates/model_delta_client_work.py:390\u001b[0m, in \u001b[0;36mbuild_model_delta_client_work\u001b[0;34m(model_fn, optimizer, client_weighting, metrics_aggregator, loop_implementation)\u001b[0m\n\u001b[1;32m    386\u001b[0m get_hparams_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    387\u001b[0m set_hparams_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@tensorflow_computation\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 390\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mclient_update_computation\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minitial_model_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkeras_optimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m  \u001b[49m\u001b[43mclient_update\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuild_model_delta_update_with_keras_optimizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m      \u001b[49m\u001b[43mweighting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_weighting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:511\u001b[0m, in \u001b[0;36mComputationWrapper.__call__.<locals>.<lambda>\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m   provided_types \u001b[38;5;241m=\u001b[39m _to_types(args)\n\u001b[0;32m--> 511\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m fn: \u001b[43m_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapper_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovided_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_type_fn\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:236\u001b[0m, in \u001b[0;36m_wrap\u001b[0;34m(fn, wrapper_fn, parameter_types, infer_type_fn)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;66;03m# Either we have a concrete parameter type, or this is no-arg function.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   parameter_type \u001b[38;5;241m=\u001b[39m _parameter_type(parameters, parameter_types)\n\u001b[0;32m--> 236\u001b[0m   wrapped_fn \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_concrete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# When applying a decorator, the __doc__ attribute with the documentation\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# in triple-quotes is not automatically transferred from the function on\u001b[39;00m\n\u001b[1;32m    240\u001b[0m wrapped_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__doc__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:98\u001b[0m, in \u001b[0;36m_wrap_concrete\u001b[0;34m(fn, wrapper_fn, parameter_type)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m concrete_fn \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(\n\u001b[1;32m    100\u001b[0m     concrete_fn,\n\u001b[1;32m    101\u001b[0m     computation_impl\u001b[38;5;241m.\u001b[39mConcreteComputation,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue returned by the wrapper\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m result_parameter_type \u001b[38;5;241m=\u001b[39m concrete_fn\u001b[38;5;241m.\u001b[39mtype_signature\u001b[38;5;241m.\u001b[39mparameter\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/environments/tensorflow_frontend/tensorflow_computation.py:79\u001b[0m, in \u001b[0;36m_tf_wrapper_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     74\u001b[0m fn \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mwrap_as_zero_or_one_arg_callable(\n\u001b[1;32m     75\u001b[0m     fn, parameter_type, unpack\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m context_stack \u001b[38;5;241m=\u001b[39m context_stack_impl\u001b[38;5;241m.\u001b[39mcontext_stack\n\u001b[1;32m     78\u001b[0m comp_pb, extra_type_spec \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mtensorflow_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_py_fn_as_tf_computation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_stack\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m computation_impl\u001b[38;5;241m.\u001b[39mConcreteComputation(\n\u001b[1;32m     84\u001b[0m     computation_proto\u001b[38;5;241m=\u001b[39mcomp_pb,\n\u001b[1;32m     85\u001b[0m     context_stack\u001b[38;5;241m=\u001b[39mcontext_stack,\n\u001b[1;32m     86\u001b[0m     annotated_type\u001b[38;5;241m=\u001b[39mextra_type_spec,\n\u001b[1;32m     87\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/environments/tensorflow_frontend/tensorflow_serialization.py:108\u001b[0m, in \u001b[0;36mserialize_py_fn_as_tf_computation\u001b[0;34m(fn, parameter_type, context_stack)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m variable_utils\u001b[38;5;241m.\u001b[39mrecord_variable_creation_scope() \u001b[38;5;28;01mas\u001b[39;00m all_variables:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m parameter_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameter_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn()\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/function_utils.py:464\u001b[0m, in \u001b[0;36mwrap_as_zero_or_one_arg_callable.<locals>.<lambda>\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgs to be bound must be in scope.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m arg: \u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/function_utils.py:457\u001b[0m, in \u001b[0;36mwrap_as_zero_or_one_arg_callable.<locals>._call\u001b[0;34m(fn, parameter_type, arg, unpack)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(fn, parameter_type, arg, unpack):\n\u001b[1;32m    456\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m unpack_arg(fn, parameter_type, arg, unpack)\n\u001b[0;32m--> 457\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/templates/model_delta_client_work.py:397\u001b[0m, in \u001b[0;36mbuild_model_delta_client_work.<locals>.client_update_computation\u001b[0;34m(initial_model_weights, dataset)\u001b[0m\n\u001b[1;32m    391\u001b[0m keras_optimizer \u001b[38;5;241m=\u001b[39m optimizer()\n\u001b[1;32m    392\u001b[0m client_update \u001b[38;5;241m=\u001b[39m build_model_delta_update_with_keras_optimizer(\n\u001b[1;32m    393\u001b[0m     model_fn\u001b[38;5;241m=\u001b[39mmodel_fn,\n\u001b[1;32m    394\u001b[0m     weighting\u001b[38;5;241m=\u001b[39mclient_weighting,\n\u001b[1;32m    395\u001b[0m     loop_implementation\u001b[38;5;241m=\u001b[39mloop_implementation,\n\u001b[1;32m    396\u001b[0m )\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_model_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file22hh3uzg.py:65\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__client_update\u001b[0;34m(optimizer, initial_weights, data)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fscope_2\u001b[38;5;241m.\u001b[39mret(retval__2, do_return_2)\n\u001b[0;32m---> 65\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_reduce_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduce_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state_for_reduce_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m client_update \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure, (ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msubtract, ag__\u001b[38;5;241m.\u001b[39mld(initial_weights)\u001b[38;5;241m.\u001b[39mtrainable, ag__\u001b[38;5;241m.\u001b[39mld(model_weights)\u001b[38;5;241m.\u001b[39mtrainable), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     67\u001b[0m (client_update, has_non_finite_delta) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tensor_utils)\u001b[38;5;241m.\u001b[39mzero_all_if_any_non_finite, (ag__\u001b[38;5;241m.\u001b[39mld(client_update),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileyskz9j2e.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___dataset_reduce_fn\u001b[0;34m(reduce_fn, dataset, initial_state_fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(dataset)\u001b[38;5;241m.\u001b[39mreduce, (), \u001b[38;5;28mdict\u001b[39m(initial_state\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(initial_state_fn), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), reduce_func\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(reduce_fn)), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file22hh3uzg.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__client_update.<locals>.reduce_fn\u001b[0;34m(num_examples_sum, batch)\u001b[0m\n\u001b[1;32m     21\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 23\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(output)\u001b[38;5;241m.\u001b[39mloss, ag__\u001b[38;5;241m.\u001b[39mld(model_weights)\u001b[38;5;241m.\u001b[39mtrainable), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n\u001b[1;32m     25\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(model_weights)\u001b[38;5;241m.\u001b[39mtrainable), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_xridjsi.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__forward_pass\u001b[0;34m(self, batch_input, training)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_forward_pass, (ag__\u001b[38;5;241m.\u001b[39mld(batch_input),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1yilto3w.py:116\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___forward_pass\u001b[0;34m(self, batch_input, training)\u001b[0m\n\u001b[1;32m    114\u001b[0m i \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m loss_wt \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_wt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1yilto3w.py:107\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___forward_pass.<locals>.if_body_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m i \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m loss_wt \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_wt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1yilto3w.py:79\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___forward_pass.<locals>.if_body_4.<locals>.if_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m batch_loss\n\u001b[1;32m     78\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_loss_fns[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39madd_n, ([\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_keras_model\u001b[38;5;241m.\u001b[39mlosses,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py:143\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m in_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(y_pred)\n\u001b[1;32m    146\u001b[0m out_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(losses)\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py:270\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    263\u001b[0m     y_pred, y_true \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[1;32m    264\u001b[0m         y_pred, y_true\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m ag_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    269\u001b[0m )\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mag_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py:1706\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1704\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_pred)\n\u001b[1;32m   1705\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(y_true, y_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mmean(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquared_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/templates/model_delta_client_work.py\", line 196, in reduce_fn  *\n        output = model.forward_pass(batch, training=True)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/loop_builder.py\", line 47, in _dataset_reduce_fn  *\n        return dataset.reduce(initial_state=initial_state_fn(), reduce_func=reduce_fn)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/models/keras_utils.py\", line 499, in forward_pass  *\n        return self._forward_pass(batch_input, training=training)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/tensorflow_federated/python/learning/models/keras_utils.py\", line 462, in _forward_pass  *\n        batch_loss = tf.add_n(\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ubuntu/miniconda3/envs/cnsm/lib/python3.10/site-packages/keras/src/losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 21 and 22 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](StatefulPartitionedCall, batch_input_1)' with input shapes: [?,21,21,1], [?,22,22,1].\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for scale_factor in [3, 4]:\n",
    "    for num_clients in range(2, 11):\n",
    "\n",
    "        # Define the TFF model\n",
    "        def model_fn():\n",
    "            keras_model = edsr(input_depth=1, scale=scale_factor, num_filters=64, num_res_blocks=8)\n",
    "            return tff.learning.models.from_keras_model(\n",
    "                keras_model,\n",
    "                input_spec=(\n",
    "                    tf.TensorSpec(shape=(None, coarse_matrix_size, coarse_matrix_size, 1), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(None, fine_matrix_size, fine_matrix_size, 1), dtype=tf.float32)\n",
    "                ),\n",
    "                loss=tf.keras.losses.MeanSquaredError(),\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    "            )\n",
    "\n",
    "        def create_tf_dataset_for_client(client_data):\n",
    "            def batch_format_fn(x, y):\n",
    "                return (x, y)\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(client_data)\n",
    "            dataset = dataset.shuffle(buffer_size=len(client_data[0]))\n",
    "            dataset = dataset.batch(32)\n",
    "            dataset = dataset.map(batch_format_fn)\n",
    "            return dataset\n",
    "\n",
    "        # Load and preprocess your data\n",
    "        train_file = f'{dataset}_coarse_{original_size//scale_factor}_x{scale_factor}.npy'\n",
    "        train_set = np.load(os.path.join(path_to_data, train_file)).astype(np.float32)\n",
    "        train_ground_truth = np.load(os.path.join(path_to_data, ground_truth)).astype(np.float32)\n",
    "\n",
    "        train_set = train_set.reshape((-1, original_size//scale_factor, original_size//scale_factor, 1))\n",
    "        train_ground_truth = train_ground_truth.reshape((-1, original_size, original_size, 1))\n",
    "\n",
    "        print(f\"Train set shape: {train_set.shape}\", \"Ground truth shape:\", train_ground_truth.shape)\n",
    "\n",
    "        train_set = preprocess(train_set)\n",
    "        train_ground_truth = preprocess(train_ground_truth)\n",
    "\n",
    "        # Create client data\n",
    "        client_data = create_client_data(train_ground_truth, train_set, num_clients)\n",
    "\n",
    "        # Print the shape of the client data\n",
    "        for i, client in enumerate(client_data):\n",
    "            print(f\"Client {i} LR:\", client[0].shape, \"Client {i} HR:\", client[1].shape)\n",
    "\n",
    "        # Shapes of the client data\n",
    "        coarse_matrix_size = client_data[0][0].shape[1]\n",
    "        fine_matrix_size = client_data[0][1].shape[1]\n",
    "\n",
    "        # Convert all clients data to float 32\n",
    "        client_data = [(x.astype(np.float32), y.astype(np.float32)) for x, y in client_data]\n",
    "        federated_train_data = [create_tf_dataset_for_client(cd) for cd in client_data]\n",
    "\n",
    "        # Create the federated learning process\n",
    "        iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "            model_fn,\n",
    "            client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        )\n",
    "\n",
    "        # Initialize the server state\n",
    "        state = iterative_process.initialize()\n",
    "\n",
    "        # Perform federated training\n",
    "        NUM_ROUNDS = 20\n",
    "        start = time.time()\n",
    "        for round_num in range(NUM_ROUNDS):\n",
    "            state, metrics = iterative_process.next(state, federated_train_data)\n",
    "            print(f'Round {round_num}')\n",
    "            print(metrics)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Training time: {end - start}\")\n",
    "        # Save training time\n",
    "        save_pickle(end - start, f'CNSM/fed_data/{dataset}_fed_training_time_{num_clients}_x{scale_factor}_rounds_{NUM_ROUNDS}.pkl')\n",
    "        # Save the federated weights\n",
    "        fed_weights = state[0].trainable\n",
    "        # Save weights\n",
    "        save_pickle(fed_weights, f'CNSM/fed_data/{dataset}_fed_weights_{num_clients}_x{scale_factor}_rounds_{NUM_ROUNDS}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
